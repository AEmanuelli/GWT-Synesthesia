{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "72c6c049-fa9d-4add-8156-7ec359734532",
      "metadata": {
        "id": "72c6c049-fa9d-4add-8156-7ec359734532"
      },
      "source": [
        "# How to train your Globalâ€¯Workspace\n",
        "Benjamin Devillers\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ruflab/shimmer-tutorials/blob/main/simple-shapes-dataset-training.ipynb)\n",
        "\n",
        "\n",
        "In this notebook, we will see how to use `shimmer` to build and train from scratch a Global Workspace on the Simple Shapes Dataset. We train a model than can translate visual images of shapes from the [simple-shapes-datset](https://github.com/ruflab/simple-shapes-dataset) to their proto-language (attributes)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e7893c3-98e4-47ba-96bb-13f2652e45c6",
      "metadata": {
        "id": "8e7893c3-98e4-47ba-96bb-13f2652e45c6"
      },
      "source": [
        "For this tutorial, we will need to install the [shimmer-ssd](https://github.com/ruflab/shimmer-ssd) package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "99e2a857-f0a5-4b98-aa95-2e12bf15fb87",
      "metadata": {
        "id": "99e2a857-f0a5-4b98-aa95-2e12bf15fb87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: /home/alexis/Desktop/.conda_local_color/bin/pip: /home/alexis/Desktop/.conda/bin/python3.11: bad interpreter: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!pip install --force-reinstall \"git+https://github.com/ruflab/shimmer-ssd.git\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7fef0c8c-3381-4b8c-896f-1ae2b443db61",
      "metadata": {
        "id": "7fef0c8c-3381-4b8c-896f-1ae2b443db61",
        "outputId": "d44a8aad-9bbe-4e4d-d5d1-e4789fd91dda"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17deebf1-86e1-46db-bc91-820158d36bcc",
      "metadata": {
        "id": "17deebf1-86e1-46db-bc91-820158d36bcc"
      },
      "source": [
        "This package depends on [simple-shapes-dataset](https://github.com/ruflab/simple-shapes-dataset) and provides all of its commands. You can then use all of its commands.\n",
        "\n",
        "For instance, we can download the dataset directly with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "80bf4524-db6c-439c-a491-0e5883b0861c",
      "metadata": {
        "id": "80bf4524-db6c-439c-a491-0e5883b0861c"
      },
      "outputs": [],
      "source": [
        "# !shapesd download"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c29130f4-ac61-460c-bc7f-cd0f7437fd5e",
      "metadata": {
        "id": "c29130f4-ac61-460c-bc7f-cd0f7437fd5e"
      },
      "source": [
        "Note that `shapesd download` automatically migrates the dataset so that it is correctly formatted. If you downloaded the dataset manually, use `shapesd migrate -p PATH_TO_DATASET` to migrate manually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "75a2017e-7de7-4568-87dd-23bf4f93a0cc",
      "metadata": {
        "editable": true,
        "id": "75a2017e-7de7-4568-87dd-23bf4f93a0cc",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/alexis/Desktop/.conda_local_color/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from collections.abc import Mapping, Sequence\n",
        "from pathlib import Path\n",
        "from typing import Any, cast\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from lightning.pytorch import Callback, Trainer, seed_everything\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "from lightning.pytorch.loggers import TensorBoardLogger\n",
        "from shimmer import DomainModule, LossOutput\n",
        "from shimmer.modules.domain import DomainModule\n",
        "from shimmer.modules.global_workspace import GlobalWorkspace2Domains, SchedulerArgs\n",
        "from shimmer.modules.vae import (\n",
        "    VAE,\n",
        "    VAEDecoder,\n",
        "    VAEEncoder,\n",
        "    gaussian_nll,\n",
        "    kl_divergence_loss,\n",
        ")\n",
        "from shimmer_ssd import DEBUG_MODE, LOGGER, PROJECT_DIR\n",
        "from shimmer_ssd.config import DomainModuleVariant, LoadedDomainConfig, load_config\n",
        "from shimmer_ssd.dataset.pre_process import TokenizeCaptions\n",
        "from shimmer_ssd.logging import (\n",
        "    LogAttributesCallback,\n",
        "    LogGWImagesCallback,\n",
        "    LogVisualCallback,\n",
        "    batch_to_device,\n",
        ")\n",
        "from shimmer_ssd.modules.domains import load_pretrained_domains\n",
        "from shimmer_ssd.modules.domains.visual import VisualLatentDomainModule\n",
        "from shimmer_ssd.modules.vae import RAEDecoder, RAEEncoder\n",
        "from tokenizers.implementations.byte_level_bpe import ByteLevelBPETokenizer\n",
        "from torch import nn\n",
        "from torch.nn.functional import mse_loss\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "from simple_shapes_dataset import SimpleShapesDataModule, get_default_domains\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8d9c35d-7b83-4ab3-9da2-9bc220a5ad87",
      "metadata": {
        "id": "b8d9c35d-7b83-4ab3-9da2-9bc220a5ad87"
      },
      "source": [
        "## Config\n",
        "\n",
        "Let's first generate the config folder for the rest of the scripts.\n",
        "This will create a `config` folder with different yaml files used by the different scripts and in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b9272822-413b-4580-bf0e-93a117112e67",
      "metadata": {
        "id": "b9272822-413b-4580-bf0e-93a117112e67",
        "outputId": "dbe6c78e-c736-418a-a5f2-4159feadc0d6",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# !ssd config create"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01bd8041-8e59-429e-9c6c-e8b656ecbbb7",
      "metadata": {
        "id": "01bd8041-8e59-429e-9c6c-e8b656ecbbb7"
      },
      "source": [
        "This will create a `config` folder. This contains many file, but in this tutorial, only `main.yaml` will interest us.\n",
        "\n",
        "You can start by taking a look at the default values which should be mostly set correctly for this tutorial. But you can try and make some changes to see the outcome.\n",
        "\n",
        "<div class=\"alert alert-info\">\n",
        "Anytime you make a change to the config, don't forget to reload it with the following cell!\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e7246f6e-a4ac-4e01-9778-d75021c698e4",
      "metadata": {
        "id": "e7246f6e-a4ac-4e01-9778-d75021c698e4"
      },
      "outputs": [],
      "source": [
        "# We don't use cli in the notebook, but consider using it in normal scripts.\n",
        "config = load_config(\"./config\", use_cli=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15df99ca-896c-4443-8ed4-da143578aa50",
      "metadata": {
        "id": "15df99ca-896c-4443-8ed4-da143578aa50"
      },
      "source": [
        "## Data format\n",
        "\n",
        "The dataloader provides the data in a specific format:\n",
        "\n",
        "```python\n",
        "domain_group = {\n",
        "    \"domain\": domain_data\n",
        "}\n",
        "batch = {\n",
        "    frozenset([\"domain\"]): domain_group\n",
        "}\n",
        "```\n",
        "* The **batch** is a dict that has frozensets of domains as keys, and a domain group as values.\n",
        "* The **domain group** is a dict that has domains (string) as keys, and the domain data as values. The data samples of every domain in a domain group is matched. This\n",
        "means that for a domain group that has 2 domains d1 and d2: `domain_group[\"d1\"][k]` is paired with `domain_group[\"d2\"][k]` for all `k`.\n",
        "\n",
        "This allows a batch to have several groups (of different domains) of paired data. For example, a batch with unpaired visual (domain \"v\"), unpaired attribute (domain \"attr\"), and paired visual and attribute will look like:\n",
        "```python\n",
        "batch = {\n",
        "    frozenset([\"v\"]): {\"v\": unpaired_visual_data},\n",
        "    frozenset([\"attr\"]): {\"attr\": unpaired_attribute_data},\n",
        "    frozenset([\"attr\", \"v\"]): {\"attr\": paired_attr_data, \"v\": paired_visual_data},\n",
        "}\n",
        "```\n",
        "\n",
        "This is useful to train the global workspace later. But this is also the format used to train the unimodal domains.\n",
        "\n",
        "Note that because all the data is paired in validation and test steps, the dataloader only returns one domain group with all paired domain:\n",
        "```python\n",
        "val_batch = {\"attr\": paired_attr_data, \"v\": paired_v_data}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17937142-b242-4cce-8122-372c8dc88baf",
      "metadata": {
        "id": "17937142-b242-4cce-8122-372c8dc88baf"
      },
      "source": [
        "## Train a Global Workspace\n",
        "\n",
        "Now that we trained our two unimodal modules, we will train the global workspace. For this training, we will use half of the paired 500,000 samples.\n",
        "To this extent, we need to create a split in the dataset. A dataset split depends on a seed and the proportion of each group of domain.\n",
        "We only need to generate this split once.\n",
        "\n",
        "This can be done with the `shapesd alignment add` command. It needs the following arguments:\n",
        "- `--dataset_path \"DATASET_PATH\"`: the location where the dataset is stored\n",
        "- `--seed SEED` the split seed\n",
        "- `--domain_alignment DOMAIN_1,DOMAIN_2,...DOMAIN_N PROP` the proportion for each domain group. This corresponds to what has been defined in `domain_proportion`\n",
        "\n",
        "When running this command, it will create a file containing the indices of the items available in the train set (update so that it matches what we set in the config file)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ea1d63eb-c931-484f-81da-58edfc090122",
      "metadata": {
        "id": "ea1d63eb-c931-484f-81da-58edfc090122"
      },
      "outputs": [],
      "source": [
        "# !shapesd alignment add --dataset_path \"simple_shapes_dataset\" --seed 0 --domain_alignment attr 1.0 --domain_alignment v 1.0 --domain_alignment attr,v 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "565b121c-f7a5-4bd3-a279-22616387b19a",
      "metadata": {
        "id": "565b121c-f7a5-4bd3-a279-22616387b19a"
      },
      "source": [
        "This time, we will load the config from the extra file `train_gw.yaml`\n",
        "\n",
        "First, let's update `main.yaml` to use the same alignment split:\n",
        "```yaml\n",
        "domain_proportions:\n",
        "    -   domains: [\"v\"]  # unimodal visual passes use 100% of the available data\n",
        "        proportion: 1.0\n",
        "    -   domains: [\"attr\"]  # unimodal attr passes use 100% of the available data\n",
        "        proportion: 1.0\n",
        "    -   domains: [\"v\", \"attr\"]  # paired passes uses 50% of the available data\n",
        "        proportion: 0.5\n",
        "```\n",
        "\n",
        "let's change the selected domains:\n",
        "\n",
        "```yaml\n",
        "domains:\n",
        "    - checkpoint_path: \"./checkpoints/visual/version_0/last.ckpt\"  # update to the actual version\n",
        "      domain_type: v_latents\n",
        "    - checkpoint_path: \"./checkpoints/attr/version_0/last.ckpt\"  # update to the actual version\n",
        "      domain_type: attr\n",
        "```\n",
        "\n",
        "and let's define the global workspace dimenison to 12:\n",
        "```yaml\n",
        "global_workspace:\n",
        "    latent_dim: 12  \n",
        "    \n",
        "    loss_coefficients:\n",
        "        cycles: 1.0\n",
        "        contrastives: 0.1\n",
        "        demi_cycles: 1.0\n",
        "        translations: 1.0\n",
        "\n",
        "    encoders:\n",
        "        hidden_dim: 32\n",
        "        n_layers: 3\n",
        "\n",
        "    decoders:\n",
        "        hidden_dim: 32\n",
        "        n_layers: 3\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb9d8076-115a-4182-bbb8-2599eb49feef",
      "metadata": {
        "id": "cb9d8076-115a-4182-bbb8-2599eb49feef"
      },
      "source": [
        "Finally, let's load the config:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0fde1645-60f5-445a-bb50-db1a97de23eb",
      "metadata": {
        "id": "0fde1645-60f5-445a-bb50-db1a97de23eb"
      },
      "outputs": [],
      "source": [
        "config = load_config(\"./config\", use_cli=False, load_files=[\"train_gw.yaml\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72288032-8119-47eb-8721-02490b88152d",
      "metadata": {
        "id": "72288032-8119-47eb-8721-02490b88152d"
      },
      "source": [
        "Skip the following cell if you have trained the unimodal module yourself. The next cell setups pretrained modules."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0eaa95a-8f85-4cbf-9c12-88911f720a7c",
      "metadata": {
        "id": "c0eaa95a-8f85-4cbf-9c12-88911f720a7c",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Run this if you did't train the modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "02e5f922-eb18-4713-a6b6-f2bbda61d5e5",
      "metadata": {
        "id": "02e5f922-eb18-4713-a6b6-f2bbda61d5e5",
        "outputId": "b756c600-dade-4f0b-f1db-8514d6afb90b"
      },
      "outputs": [],
      "source": [
        "# # Download checkpoints\n",
        "# !ssd download checkpoints\n",
        "# !mv checkpoints/checkpoints/* checkpoints/\n",
        "# !rm -rf checkpoints/checkpoints\n",
        "\n",
        "# # Extract visual latent from pretrained visual domain\n",
        "# !ssd extract v \"checkpoints/domain_v.ckpt\" -p \"simple_shapes_dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c21fe165-5f6c-470b-9a6e-ec17789a2799",
      "metadata": {
        "id": "c21fe165-5f6c-470b-9a6e-ec17789a2799"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Update the config\n",
        "checkpoint_path = Path(\"./checkpoints\")\n",
        "config = load_config(\"./config\", use_cli=False, load_files=[\"train_gw.yaml\"])\n",
        "config.domain_proportions = {\n",
        "    frozenset([\"v\"]): 1.0,\n",
        "    frozenset([\"attr\"]): 1.0,\n",
        "    frozenset([\"v\", \"attr\"]): 1.0,\n",
        "}\n",
        "\n",
        "config.domains = [\n",
        "    LoadedDomainConfig(\n",
        "        domain_type=DomainModuleVariant.v_latents,\n",
        "        checkpoint_path=checkpoint_path / \"domain_v.ckpt\",\n",
        "    ),\n",
        "    LoadedDomainConfig(\n",
        "        domain_type=DomainModuleVariant.attr_legacy,\n",
        "        checkpoint_path=checkpoint_path / \"domain_attr.ckpt\",\n",
        "    ),\n",
        "]\n",
        "\n",
        "config.domain_data_args[\"v_latents\"][\"presaved_path\"] = \"domain_v.npy\"\n",
        "config.global_workspace.latent_dim = 12"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14e86345-5644-4007-87fe-5f7a143f4d41",
      "metadata": {
        "id": "14e86345-5644-4007-87fe-5f7a143f4d41"
      },
      "source": [
        "### Load the domains and train\n",
        "We can now load the pretrained unimodal modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e1135c58-53b1-4c8f-9b76-373128d7f218",
      "metadata": {
        "id": "e1135c58-53b1-4c8f-9b76-373128d7f218"
      },
      "outputs": [],
      "source": [
        "# we load the pretrained domain modules and define the associated GW encoders and decoders\n",
        "domain_modules, gw_encoders, gw_decoders = load_pretrained_domains(\n",
        "    config.domains,\n",
        "    config.global_workspace.latent_dim,\n",
        "    config.global_workspace.encoders.hidden_dim,\n",
        "    config.global_workspace.encoders.n_layers,\n",
        "    config.global_workspace.decoders.hidden_dim,\n",
        "    config.global_workspace.decoders.n_layers,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebe7e3df-37c9-401b-a481-38609c18ceff",
      "metadata": {
        "id": "ebe7e3df-37c9-401b-a481-38609c18ceff"
      },
      "source": [
        "Instanciate the global Workspace class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3c26a008-3d9e-4676-bfb1-5364bbe8e752",
      "metadata": {
        "id": "3c26a008-3d9e-4676-bfb1-5364bbe8e752"
      },
      "outputs": [],
      "source": [
        "def get_scheduler(optimizer: Optimizer) -> OneCycleLR:\n",
        "    return OneCycleLR(optimizer, config.training.optim.max_lr, config.training.max_steps)\n",
        "\n",
        "\n",
        "global_workspace = GlobalWorkspace2Domains(\n",
        "    domain_modules,\n",
        "    gw_encoders,\n",
        "    gw_decoders,\n",
        "    config.global_workspace.latent_dim,\n",
        "    config.global_workspace.loss_coefficients,\n",
        "    config.training.optim.lr,\n",
        "    config.training.optim.weight_decay,\n",
        "    scheduler=get_scheduler,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "afa51800",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import default_collate\n",
        "\n",
        "def custom_collate(batch):\n",
        "    collated = default_collate(batch)\n",
        "    if isinstance(collated, dict) and \"attr\" in collated:\n",
        "        # Si \"attr\" est une liste et contient au moins deux tenseurs,\n",
        "        # on modifie uniquement le deuxiÃ¨me tenseur.\n",
        "        if isinstance(collated[\"attr\"], list) and len(collated[\"attr\"]) >= 2:\n",
        "            second_tensor = collated[\"attr\"][1]\n",
        "            if isinstance(second_tensor, torch.Tensor):\n",
        "                # On enlÃ¨ve les trois valeurs situÃ©es juste avant la derniÃ¨re.\n",
        "                if second_tensor.size(-1) >= 4:  # vÃ©rifie qu'il y a assez d'Ã©lÃ©ments\n",
        "                    collated[\"attr\"][1] = torch.cat(\n",
        "                        [second_tensor[..., : -4], second_tensor[..., -1:]], dim=-1\n",
        "                    )\n",
        "    return collated\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9171f84d-e76e-44e7-95c7-246f064e664d",
      "metadata": {
        "id": "9171f84d-e76e-44e7-95c7-246f064e664d"
      },
      "outputs": [],
      "source": [
        "domain_classes = get_default_domains([\"v_latents\", \"attr\"])\n",
        "\n",
        "data_module = SimpleShapesDataModule(\n",
        "    config.dataset.path,\n",
        "    domain_classes,\n",
        "    config.domain_proportions,\n",
        "    batch_size=config.training.batch_size,\n",
        "    num_workers=config.training.num_workers,\n",
        "    seed=config.seed,\n",
        "    domain_args=config.domain_data_args,\n",
        "    # collate_fn=custom_collate  # utilisation du collate personnalisÃ©\n",
        ")\n",
        "\n",
        "# print(data_module.batch_size)\n",
        "# print(data_module.domain_args)\n",
        "# data_module.setup()\n",
        "\n",
        "# # batch, _, _ = next(iter(data_module.train_dataloader()))\n",
        "# print(batch.keys())\n",
        "# print(batch[frozenset([\"attr\"])][\"attr\"][0].shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcf92cee-a17a-4db2-960b-91e375235de5",
      "metadata": {
        "id": "fcf92cee-a17a-4db2-960b-91e375235de5"
      },
      "source": [
        "Add a Wandb logger to follow the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "145c0039-b27a-4ab3-a262-abb87a00d152",
      "metadata": {
        "id": "145c0039-b27a-4ab3-a262-abb87a00d152"
      },
      "outputs": [],
      "source": [
        "from lightning.pytorch.loggers.wandb import WandbLogger\n",
        "\n",
        "# logger = TensorBoardLogger(\"logs\", name=\"gw\")\n",
        "logger_wandb = WandbLogger(name=\"gw\", project=\"shimmer-ssd\")\n",
        "logger = logger_wandb\n",
        "# Get some image samples to log in tensorboard.\n",
        "train_samples = data_module.get_samples(\"train\", 32)\n",
        "val_samples = data_module.get_samples(\"val\", 32)\n",
        "\n",
        "# split the unique group in validation into individual groups for logging\n",
        "for domains in val_samples:\n",
        "    for domain in domains:\n",
        "        val_samples[frozenset([domain])] = {domain: val_samples[domains][domain]}\n",
        "    break\n",
        "# Create attr folder where we will save checkpoints\n",
        "(config.default_root_dir / \"gw\").mkdir(exist_ok=True)\n",
        "\n",
        "callbacks: list[Callback] = [\n",
        "    # Will log the validation ground-truth and reconstructions during training\n",
        "    LogGWImagesCallback(\n",
        "        val_samples,\n",
        "        log_key=\"images/val\",\n",
        "        mode=\"val\",\n",
        "        every_n_epochs=config.logging.log_val_medias_every_n_epochs,\n",
        "        filter=config.logging.filter_images,\n",
        "    ),\n",
        "    # Will log the training ground-truth and reconstructions during training\n",
        "    LogGWImagesCallback(\n",
        "        train_samples,\n",
        "        log_key=\"images/train\",\n",
        "        mode=\"train\",\n",
        "        every_n_epochs=config.logging.log_train_medias_every_n_epochs,\n",
        "        filter=config.logging.filter_images,\n",
        "    ),\n",
        "    # Save the checkpoints\n",
        "    ModelCheckpoint(\n",
        "        dirpath=config.default_root_dir / \"gw\" / f\"version_{logger.version}\",\n",
        "        filename=\"{epoch}\",\n",
        "        monitor=\"val/loss\",\n",
        "        mode=\"min\",\n",
        "        save_last=\"link\",\n",
        "        save_top_k=1,\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59ae4778-9615-4415-abad-420787e66d2c",
      "metadata": {
        "id": "59ae4778-9615-4415-abad-420787e66d2c"
      },
      "source": [
        "For the final model, let's save where the model is saved:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "b98b6642-ae5c-4cf8-9600-07882cd9d4ec",
      "metadata": {
        "id": "b98b6642-ae5c-4cf8-9600-07882cd9d4ec",
        "outputId": "30462a78-a1c8-4cb6-c259-f16fb1a6ae32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoints/gw/version_None\n"
          ]
        }
      ],
      "source": [
        "gw_checkpoint = config.default_root_dir / \"gw\" / f\"version_{logger.version}\"\n",
        "print(gw_checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82764468-75c4-4403-89e4-269ac0ae8779",
      "metadata": {
        "id": "82764468-75c4-4403-89e4-269ac0ae8779"
      },
      "source": [
        "And train!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf6de9e3-d4cd-4246-94df-4a677f8866b0",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "7907157ed2404360bf6613ae4ec30311",
            "cb1c358b657c455a858e60ece12ec8df",
            "ded8b395310e45e4af1c5c431ce9b690",
            "7090a88b7bef4a8eae426b6f75b40d53",
            "168c9a4c1b0947f380aa144870b73ff2",
            "7f6211c008094ca6a40317512fe61a2f",
            "ef158f26eeb64474b6e51ba63bfcaef1",
            "13e689c08e394397af715204465f59b6",
            "d962c807781f4395bd6bf2b8f347086d",
            "a0644a5109824e8e83c1ee8036ca514b",
            "52bc46a04be341ed8a0d15cc14bed750",
            "f6c05a13b84b46898ae335e20ee770d6",
            "60716e33b618458580f2598a2bc8c791",
            "344f12f6e53543fbb3387a6fb97d4050",
            "c133bbdc6a4e4beda39f3f8cc9da445c",
            "6db128282910453d9a4d2619c2735dfa",
            "e0155604002a4c6a82cd6a956cb69c32",
            "bf332f64b7e440d1879afdbe13ec541f",
            "9aae6d0b529e444dad67175751482134",
            "a868fc8fdf1046d99ed0e1bfe84972e2",
            "0bac39da29ef493aac4775a930660ae2",
            "2af3de4d9e2c4285878b446b3dc32712",
            "db30c0cbe8d14daebc8e4f0544dfb449",
            "9771ca8e88054908b1816f3e5b1239a6",
            "d6bc9b0e9f6a4b2f89993a1eb7c146a4",
            "cdb595c0656c4bc690871dc06593f042",
            "b51ee9eb61994ed1b9a21bdd22bc558a",
            "03cc2149c4cc41518ac143da639fbf46",
            "790313dd30b84f1f9bb64eaf6cac3332",
            "fb76922e4a2f4f5498a994f91ca9ac2e",
            "2109394bd6c54dd09d15193071b060e0",
            "b3d40700f5fd404397d5ae5f3062e67e",
            "73eeb98b5b824d84a839a8b900c44188",
            "8a7ac49f2ba3448e9e44217cd9750fb1",
            "525644d135df4a119f87afc7502ef1dd"
          ]
        },
        "id": "cf6de9e3-d4cd-4246-94df-4a677f8866b0",
        "outputId": "e18fabeb-56ab-4f6d-968b-5c505e8cef02",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlexman\u001b[0m (\u001b[33mlexman-psl\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>./wandb/run-20250317_145753-hh2wbnpa</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/lexman-psl/Shimmer-SSD/runs/hh2wbnpa' target=\"_blank\">gw</a></strong> to <a href='https://wandb.ai/lexman-psl/Shimmer-SSD' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/lexman-psl/Shimmer-SSD' target=\"_blank\">https://wandb.ai/lexman-psl/Shimmer-SSD</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/lexman-psl/Shimmer-SSD/runs/hh2wbnpa' target=\"_blank\">https://wandb.ai/lexman-psl/Shimmer-SSD/runs/hh2wbnpa</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/alexis/Desktop/.conda_local_color/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /home/alexis/Desktop/checkpoints/gw/version_None exists and is not empty.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
            "\n",
            "  | Name          | Type                  | Params | Mode \n",
            "----------------------------------------------------------------\n",
            "0 | gw_mod        | GWModule              | 5.8 M  | train\n",
            "1 | selection_mod | SingleDomainSelection | 0      | train\n",
            "2 | loss_mod      | GWLosses2Domains      | 5.8 M  | train\n",
            "----------------------------------------------------------------\n",
            "14.8 K    Trainable params\n",
            "5.8 M     Non-trainable params\n",
            "5.8 M     Total params\n",
            "23.376    Total estimated model params size (MB)\n",
            "50        Modules in train mode\n",
            "35        Modules in eval mode\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/243 [00:00<?, ?it/s]                           "
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    logger=logger,\n",
        "    max_steps=config.training.max_steps,\n",
        "    default_root_dir=config.default_root_dir,\n",
        "    callbacks=callbacks,\n",
        "    precision=config.training.precision,\n",
        "    accelerator=config.training.accelerator,\n",
        "    devices=config.training.devices,\n",
        ")\n",
        "\n",
        "trainer.fit(global_workspace, data_module)\n",
        "trainer.validate(global_workspace, data_module, \"best\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8586bbec",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Quel type de modÃ¨le ?\n",
        "MODEL_TYPE = \"sans_couleur\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2952da96",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'x' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[59], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m domain_type \u001b[38;5;241m=\u001b[39m DomainModuleVariant\u001b[38;5;241m.\u001b[39mattr_legacy\n\u001b[1;32m     17\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m checkpoint_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgw/version_None/epoch=660.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m attributes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[0;32m---> 19\u001b[0m     [[\u001b[43mx\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, y \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, size \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, rotx, roty ]]\u001b[38;5;66;03m#, color_r * 2 - 1, color_g * 2 - 1, color_b * 2 - 1]]\u001b[39;00m\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     21\u001b[0m config\u001b[38;5;241m.\u001b[39mglobal_workspace\u001b[38;5;241m.\u001b[39mencoders\u001b[38;5;241m.\u001b[39mn_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     22\u001b[0m config\u001b[38;5;241m.\u001b[39mglobal_workspace\u001b[38;5;241m.\u001b[39mdecoders\u001b[38;5;241m.\u001b[39mn_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ],
      "source": [
        "# And now we load the GW checkpoint\n",
        "checkpoint_path = Path(\"./checkpoints\")\n",
        "# We don't use cli in the notebook, but consider using it in normal scripts.\n",
        "config = load_config(\"./config\", use_cli=False)\n",
        "\n",
        "\n",
        "if MODEL_TYPE == \"full_attr\":\n",
        "    domain_type = DomainModuleVariant.attr\n",
        "    checkpoint = checkpoint_path / \"gw-attr-v-all-paired-data.ckpt\"\n",
        "    config.global_workspace.encoders.n_layers = 3\n",
        "    config.global_workspace.decoders.n_layers = 3\n",
        "    attributes = torch.tensor(\n",
        "        [[x * 2 - 1, y * 2 - 1, size * 2 - 1, rotx, roty, color_r * 2 - 1, color_g * 2 - 1, color_b * 2 - 1]]\n",
        "    )\n",
        "else : \n",
        "    domain_type = DomainModuleVariant.attr_legacy\n",
        "    checkpoint = checkpoint_path / \"gw/version_None/epoch=660.ckpt\"\n",
        "    attributes = torch.tensor(\n",
        "        [[x * 2 - 1, y * 2 - 1, size * 2 - 1, rotx, roty ]]#, color_r * 2 - 1, color_g * 2 - 1, color_b * 2 - 1]]\n",
        "    )\n",
        "    config.global_workspace.encoders.n_layers = 3\n",
        "    config.global_workspace.decoders.n_layers = 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13117f0a",
      "metadata": {},
      "outputs": [],
      "source": [
        "#CEST UN TEST\n",
        "\n",
        "# Update the config\n",
        "checkpoint_path = Path(\"./checkpoints\")\n",
        "\n",
        "config.domain_proportions = {\n",
        "    frozenset([\"v\"]): 1.0,\n",
        "    frozenset([\"attr\"]): 1.0,\n",
        "    frozenset([\"v\", \"attr\"]): 1.0,\n",
        "}\n",
        "\n",
        "config.domains = [\n",
        "    LoadedDomainConfig(\n",
        "        domain_type=DomainModuleVariant.v_latents,\n",
        "        checkpoint_path=checkpoint_path / \"domain_v.ckpt\",\n",
        "    ),\n",
        "    LoadedDomainConfig(\n",
        "        domain_type=domain_type,\n",
        "        checkpoint_path=checkpoint_path / \"domain_attr.ckpt\",\n",
        "    ),\n",
        "]\n",
        "\n",
        "config.domain_data_args[\"v_latents\"][\"presaved_path\"] = \"domain_v.npy\"\n",
        "config.global_workspace.latent_dim = 12\n",
        "\n",
        "domain_modules, gw_encoders, gw_decoders = load_pretrained_domains(\n",
        "    config.domains,\n",
        "    config.global_workspace.latent_dim,\n",
        "    config.global_workspace.encoders.hidden_dim,\n",
        "    config.global_workspace.encoders.n_layers,\n",
        "    config.global_workspace.decoders.hidden_dim,\n",
        "    config.global_workspace.decoders.n_layers,\n",
        ")\n",
        "\n",
        "global_workspace = GlobalWorkspace2Domains.load_from_checkpoint(\n",
        "    checkpoint,\n",
        "    domain_mods=domain_modules,\n",
        "    gw_encoders=gw_encoders,\n",
        "    gw_decoders=gw_decoders,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f99d2f8-e3d4-4e42-bda0-bc949bf1d248",
      "metadata": {
        "id": "4f99d2f8-e3d4-4e42-bda0-bc949bf1d248",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Run this if you did't train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baeef54d-ab50-490d-931b-8fa8d71e9026",
      "metadata": {
        "id": "baeef54d-ab50-490d-931b-8fa8d71e9026"
      },
      "outputs": [],
      "source": [
        "# # Update the config\n",
        "# checkpoint_path = Path(\"./checkpoints\")\n",
        "\n",
        "# config.domain_proportions = {\n",
        "#     frozenset([\"v\"]): 1.0,\n",
        "#     frozenset([\"attr\"]): 1.0,\n",
        "#     frozenset([\"v\", \"attr\"]): 1.0,\n",
        "# }\n",
        "\n",
        "# config.domains = [\n",
        "#     LoadedDomainConfig(\n",
        "#         domain_type=DomainModuleVariant.v_latents,\n",
        "#         checkpoint_path=checkpoint_path / \"domain_v.ckpt\",\n",
        "#     ),\n",
        "#     LoadedDomainConfig(\n",
        "#         domain_type=DomainModuleVariant.attr_legacy,\n",
        "#         checkpoint_path=checkpoint_path / \"domain_attr.ckpt\",\n",
        "#     ),\n",
        "# ]\n",
        "\n",
        "# config.domain_data_args[\"v_latents\"][\"presaved_path\"] = \"domain_v.npy\"\n",
        "# config.global_workspace.latent_dim = 12\n",
        "# # And now we load the GW checkpoint\n",
        "# checkpoint_path = Path(\"./checkpoints\")\n",
        "# # checkpoint = checkpoint_path / \"gw-attr-v-half-paired-data.ckpt\"\n",
        "# checkpoint  = \"/home/alexis/Desktop/checkpoints/gw/version_None/epoch=120-v1.ckpt\"\n",
        "# # we load the pretrained domain modules and define the associated GW encoders and decoders\n",
        "# domain_modules, gw_encoders, gw_decoders = load_pretrained_domains(\n",
        "#     config.domains,\n",
        "#     config.global_workspace.latent_dim,\n",
        "#     config.global_workspace.encoders.hidden_dim,\n",
        "#     config.global_workspace.encoders.n_layers,\n",
        "#     config.global_workspace.decoders.hidden_dim,\n",
        "#     config.global_workspace.decoders.n_layers,\n",
        "# )\n",
        "\n",
        "# global_workspace = GlobalWorkspace2Domains.load_from_checkpoint(\n",
        "#     checkpoint,\n",
        "#     domain_mods=domain_modules,\n",
        "#     gw_encoders=gw_encoders,\n",
        "#     gw_decoders=gw_decoders,\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aefbfff6-8cbc-4a72-8e34-47c2d28f0e6d",
      "metadata": {
        "id": "aefbfff6-8cbc-4a72-8e34-47c2d28f0e6d"
      },
      "source": [
        "## Play with the global workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0cc65be-5456-4f3a-8216-0d061deec60e",
      "metadata": {
        "id": "e0cc65be-5456-4f3a-8216-0d061deec60e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipywidgets in ./.conda/lib/python3.11/site-packages (8.1.5)\n",
            "Requirement already satisfied: ipympl in ./.conda/lib/python3.11/site-packages (0.9.6)\n",
            "Requirement already satisfied: comm>=0.1.3 in /home/alexis/.local/lib/python3.11/site-packages (from ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /home/alexis/.local/lib/python3.11/site-packages (from ipywidgets) (8.32.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /home/alexis/.local/lib/python3.11/site-packages (from ipywidgets) (5.14.3)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.12 in ./.conda/lib/python3.11/site-packages (from ipywidgets) (4.0.13)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in ./.conda/lib/python3.11/site-packages (from ipywidgets) (3.0.13)\n",
            "Requirement already satisfied: matplotlib<4,>=3.5.0 in ./.conda/lib/python3.11/site-packages (from ipympl) (3.10.1)\n",
            "Requirement already satisfied: numpy in ./.conda/lib/python3.11/site-packages (from ipympl) (1.26.4)\n",
            "Requirement already satisfied: pillow in ./.conda/lib/python3.11/site-packages (from ipympl) (10.4.0)\n",
            "Requirement already satisfied: decorator in /home/alexis/.local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /home/alexis/.local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline in /home/alexis/.local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in ./.conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/alexis/.local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
            "Requirement already satisfied: pygments>=2.4.0 in ./.conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
            "Requirement already satisfied: stack_data in /home/alexis/.local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
            "Requirement already satisfied: typing_extensions>=4.6 in ./.conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.conda/lib/python3.11/site-packages (from matplotlib<4,>=3.5.0->ipympl) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in ./.conda/lib/python3.11/site-packages (from matplotlib<4,>=3.5.0->ipympl) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.conda/lib/python3.11/site-packages (from matplotlib<4,>=3.5.0->ipympl) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./.conda/lib/python3.11/site-packages (from matplotlib<4,>=3.5.0->ipympl) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.conda/lib/python3.11/site-packages (from matplotlib<4,>=3.5.0->ipympl) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.conda/lib/python3.11/site-packages (from matplotlib<4,>=3.5.0->ipympl) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./.conda/lib/python3.11/site-packages (from matplotlib<4,>=3.5.0->ipympl) (2.9.0.post0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/alexis/.local/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in ./.conda/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /home/alexis/.local/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in ./.conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib<4,>=3.5.0->ipympl) (1.17.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in /home/alexis/.local/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /home/alexis/.local/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in /home/alexis/.local/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "import io\n",
        "import math\n",
        "%pip install ipywidgets ipympl\n",
        "import ipywidgets as widgets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from ipywidgets import interact, interact_manual\n",
        "from PIL import Image\n",
        "from shimmer_ssd.logging import attribute_image_grid\n",
        "from torch.nn.functional import one_hot\n",
        "\n",
        "from simple_shapes_dataset.cli import generate_image\n",
        "%matplotlib widget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81b9ab47",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !conda install -c conda-forge ipympl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b204af9d-df27-4462-9dfc-b45d8e7eb3d5",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "d4f37e3214cb4738951b5144b9192720"
          ]
        },
        "id": "b204af9d-df27-4462-9dfc-b45d8e7eb3d5",
        "outputId": "e01d7a19-5210-4375-c399-fa20accbc5b8"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m global_workspace\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m cat2idx \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiamond\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEgg\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTriangle\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m}\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "global_workspace.to(device)\n",
        "\n",
        "cat2idx = {\"Diamond\": 0, \"Egg\": 1, \"Triangle\": 2}\n",
        "\n",
        "\n",
        "def get_image(cat, x, y, size, rot, color_r, color_g, color_b):\n",
        "    fig, ax = plt.subplots(figsize=(32, 32), dpi=1)\n",
        "    # The dataset generatoion tool has function to generate a matplotlib shape\n",
        "    # from the attributes.\n",
        "    generate_image(\n",
        "        ax,\n",
        "        cat2idx[cat],\n",
        "        [int(x * 18 + 7), int(y * 18 + 7)],\n",
        "        size * 7 + 7,\n",
        "        rot * 2 * math.pi,\n",
        "        np.array([color_r * 255, color_g * 255, color_b * 255]),\n",
        "        imsize=32,\n",
        "    )\n",
        "    ax.set_facecolor(\"black\")\n",
        "    plt.tight_layout(pad=0)\n",
        "    # Return this as a PIL Image.\n",
        "    # This is to have the same dpi as saved images\n",
        "    # otherwise matplotlib will render this in very high quality\n",
        "    buf = io.BytesIO()\n",
        "    fig.savefig(buf)\n",
        "    buf.seek(0)\n",
        "    image = Image.open(buf)\n",
        "    plt.close(fig)\n",
        "    return image\n",
        "\n",
        "\n",
        "@interact(\n",
        "    cat=[\"Triangle\", \"Egg\", \"Diamond\"],\n",
        "    x=(0, 1, 0.1),\n",
        "    y=(0, 1, 0.1),\n",
        "    rot=(0, 1, 0.1),\n",
        "    size=(0, 1, 0.1),\n",
        "    color_r=(0, 1, 0.1),\n",
        "    color_g=(0, 1, 0.1),\n",
        "    color_b=(0, 1, 0.1),\n",
        ")\n",
        "def play_with_gw(\n",
        "    cat: str = \"Triangle\",\n",
        "    x: float = 0.5,\n",
        "    y: float = 0.5,\n",
        "    rot: float = 0.5,\n",
        "    size: float = 0.5,\n",
        "    color_r: float = 1,\n",
        "    color_g: float = 0,\n",
        "    color_b: float = 0,\n",
        "):\n",
        "    fig, axes = plt.subplots(1, 2)\n",
        "    image = get_image(cat, x, y, size, rot, color_r, color_g, color_b)\n",
        "    axes[0].set_facecolor(\"black\")\n",
        "    axes[0].set_title(\"Original image from attributes\")\n",
        "    axes[0].set_xticks([])\n",
        "    axes[0].set_yticks([])\n",
        "    axes[0].imshow(image)\n",
        "\n",
        "    # normalize the attribute for the global workspace.\n",
        "    category = one_hot(torch.tensor([cat2idx[cat]]), 3)\n",
        "    rotx = math.cos(rot * 2 * math.pi)\n",
        "    roty = math.sin(rot * 2 * math.pi)\n",
        "    if MODEL_TYPE == \"full_attr\":\n",
        "        attributes = torch.tensor(\n",
        "            [[x * 2 - 1, y * 2 - 1, size * 2 - 1, rotx, roty, color_r * 2 - 1, color_g * 2 - 1, color_b * 2 - 1]]\n",
        "        )\n",
        "    else:\n",
        "        attributes = torch.tensor(\n",
        "            [[x * 2 - 1, y * 2 - 1, size * 2 - 1, rotx, roty]]  # , color_r * 2 - 1, color_g * 2 - 1, color_b * 2 - 1]]\n",
        "        )\n",
        "    samples = [category.to(device), attributes.to(device)]\n",
        "    attr_gw_latent = global_workspace.gw_mod.encode({\"attr\": global_workspace.encode_domain(samples, \"attr\")})\n",
        "    gw_latent = global_workspace.gw_mod.fuse(\n",
        "        attr_gw_latent, {\"attr\": torch.ones(attr_gw_latent[\"attr\"].size(0)).to(device)}\n",
        "    )\n",
        "    decoded_latents = global_workspace.gw_mod.decode(gw_latent)[\"v_latents\"]\n",
        "    decoded_images = (\n",
        "        global_workspace.domain_mods[\"v_latents\"]\n",
        "        .decode_images(decoded_latents)[0]\n",
        "        .permute(1, 2, 0)\n",
        "        .detach()\n",
        "        .cpu()\n",
        "        .numpy()\n",
        "    )\n",
        "    axes[1].imshow(decoded_images)\n",
        "    axes[1].set_xticks([])\n",
        "    axes[1].set_yticks([])\n",
        "    axes[1].set_title(\"Translated image through GW\")\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
