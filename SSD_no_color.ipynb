{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "72c6c049-fa9d-4add-8156-7ec359734532",
      "metadata": {
        "id": "72c6c049-fa9d-4add-8156-7ec359734532"
      },
      "source": [
        "# How to train your Global Workspace\n",
        "Benjamin Devillers\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ruflab/shimmer-tutorials/blob/main/simple-shapes-dataset-training.ipynb)\n",
        "\n",
        "\n",
        "In this notebook, we will see how to use `shimmer` to build and train from scratch a Global Workspace on the Simple Shapes Dataset. We train a model than can translate visual images of shapes from the [simple-shapes-datset](https://github.com/ruflab/simple-shapes-dataset) to their proto-language (attributes)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e7893c3-98e4-47ba-96bb-13f2652e45c6",
      "metadata": {
        "id": "8e7893c3-98e4-47ba-96bb-13f2652e45c6"
      },
      "source": [
        "For this tutorial, we will need to install the [shimmer-ssd](https://github.com/ruflab/shimmer-ssd) package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "99e2a857-f0a5-4b98-aa95-2e12bf15fb87",
      "metadata": {
        "id": "99e2a857-f0a5-4b98-aa95-2e12bf15fb87"
      },
      "outputs": [],
      "source": [
        "# !pip install --force-reinstall \"git+https://github.com/AEmanuelli/shimmer-ssd.git\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17deebf1-86e1-46db-bc91-820158d36bcc",
      "metadata": {
        "id": "17deebf1-86e1-46db-bc91-820158d36bcc"
      },
      "source": [
        "This package depends on [simple-shapes-dataset](https://github.com/ruflab/simple-shapes-dataset) and provides all of its commands. You can then use all of its commands.\n",
        "\n",
        "For instance, we can download the dataset directly with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "80bf4524-db6c-439c-a491-0e5883b0861c",
      "metadata": {
        "id": "80bf4524-db6c-439c-a491-0e5883b0861c"
      },
      "outputs": [],
      "source": [
        "# !shapesd download"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c29130f4-ac61-460c-bc7f-cd0f7437fd5e",
      "metadata": {
        "id": "c29130f4-ac61-460c-bc7f-cd0f7437fd5e"
      },
      "source": [
        "Note that `shapesd download` automatically migrates the dataset so that it is correctly formatted. If you downloaded the dataset manually, use `shapesd migrate -p PATH_TO_DATASET` to migrate manually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "75a2017e-7de7-4568-87dd-23bf4f93a0cc",
      "metadata": {
        "editable": true,
        "id": "75a2017e-7de7-4568-87dd-23bf4f93a0cc",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from collections.abc import Mapping, Sequence\n",
        "from pathlib import Path\n",
        "from typing import Any, cast\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from lightning.pytorch import Callback, Trainer, seed_everything\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "from lightning.pytorch.loggers import TensorBoardLogger\n",
        "from shimmer import DomainModule, LossOutput\n",
        "from shimmer.modules.domain import DomainModule\n",
        "from shimmer.modules.global_workspace import GlobalWorkspace2Domains, SchedulerArgs\n",
        "from shimmer.modules.vae import (\n",
        "    VAE,\n",
        "    VAEDecoder,\n",
        "    VAEEncoder,\n",
        "    gaussian_nll,\n",
        "    kl_divergence_loss,\n",
        ")\n",
        "from shimmer_ssd import DEBUG_MODE, LOGGER, PROJECT_DIR\n",
        "from shimmer_ssd.config import DomainModuleVariant, LoadedDomainConfig, load_config\n",
        "from shimmer_ssd.dataset.pre_process import TokenizeCaptions\n",
        "from shimmer_ssd.logging import (\n",
        "    LogAttributesCallback,\n",
        "    LogGWImagesCallback,\n",
        "    LogVisualCallback,\n",
        "    batch_to_device,\n",
        ")\n",
        "from shimmer_ssd.modules.domains import load_pretrained_domains\n",
        "from shimmer_ssd.modules.domains.visual import VisualLatentDomainModule\n",
        "from shimmer_ssd.modules.vae import RAEDecoder, RAEEncoder\n",
        "from tokenizers.implementations.byte_level_bpe import ByteLevelBPETokenizer\n",
        "from torch import nn\n",
        "from torch.nn.functional import mse_loss\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "from simple_shapes_dataset import SimpleShapesDataModule, get_default_domains\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8d9c35d-7b83-4ab3-9da2-9bc220a5ad87",
      "metadata": {
        "id": "b8d9c35d-7b83-4ab3-9da2-9bc220a5ad87"
      },
      "source": [
        "## Config\n",
        "\n",
        "Let's first generate the config folder for the rest of the scripts.\n",
        "This will create a `config` folder with different yaml files used by the different scripts and in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b9272822-413b-4580-bf0e-93a117112e67",
      "metadata": {
        "id": "b9272822-413b-4580-bf0e-93a117112e67",
        "outputId": "dbe6c78e-c736-418a-a5f2-4159feadc0d6",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# !ssd config create"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01bd8041-8e59-429e-9c6c-e8b656ecbbb7",
      "metadata": {
        "id": "01bd8041-8e59-429e-9c6c-e8b656ecbbb7"
      },
      "source": [
        "This will create a `config` folder. This contains many file, but in this tutorial, only `main.yaml` will interest us.\n",
        "\n",
        "You can start by taking a look at the default values which should be mostly set correctly for this tutorial. But you can try and make some changes to see the outcome.\n",
        "\n",
        "<div class=\"alert alert-info\">\n",
        "Anytime you make a change to the config, don't forget to reload it with the following cell!\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15df99ca-896c-4443-8ed4-da143578aa50",
      "metadata": {
        "id": "15df99ca-896c-4443-8ed4-da143578aa50"
      },
      "source": [
        "## Data format\n",
        "\n",
        "The dataloader provides the data in a specific format:\n",
        "\n",
        "```python\n",
        "domain_group = {\n",
        "    \"domain\": domain_data\n",
        "}\n",
        "batch = {\n",
        "    frozenset([\"domain\"]): domain_group\n",
        "}\n",
        "```\n",
        "* The **batch** is a dict that has frozensets of domains as keys, and a domain group as values.\n",
        "* The **domain group** is a dict that has domains (string) as keys, and the domain data as values. The data samples of every domain in a domain group is matched. This\n",
        "means that for a domain group that has 2 domains d1 and d2: `domain_group[\"d1\"][k]` is paired with `domain_group[\"d2\"][k]` for all `k`.\n",
        "\n",
        "This allows a batch to have several groups (of different domains) of paired data. For example, a batch with unpaired visual (domain \"v\"), unpaired attribute (domain \"attr\"), and paired visual and attribute will look like:\n",
        "```python\n",
        "batch = {\n",
        "    frozenset([\"v\"]): {\"v\": unpaired_visual_data},\n",
        "    frozenset([\"attr\"]): {\"attr\": unpaired_attribute_data},\n",
        "    frozenset([\"attr\", \"v\"]): {\"attr\": paired_attr_data, \"v\": paired_visual_data},\n",
        "}\n",
        "```\n",
        "\n",
        "This is useful to train the global workspace later. But this is also the format used to train the unimodal domains.\n",
        "\n",
        "Note that because all the data is paired in validation and test steps, the dataloader only returns one domain group with all paired domain:\n",
        "```python\n",
        "val_batch = {\"attr\": paired_attr_data, \"v\": paired_v_data}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17937142-b242-4cce-8122-372c8dc88baf",
      "metadata": {
        "id": "17937142-b242-4cce-8122-372c8dc88baf"
      },
      "source": [
        "## Train a Global Workspace\n",
        "\n",
        "Now that we trained our two unimodal modules, we will train the global workspace. For this training, we will use half of the paired 500,000 samples.\n",
        "To this extent, we need to create a split in the dataset. A dataset split depends on a seed and the proportion of each group of domain.\n",
        "We only need to generate this split once.\n",
        "\n",
        "This can be done with the `shapesd alignment add` command. It needs the following arguments:\n",
        "- `--dataset_path \"DATASET_PATH\"`: the location where the dataset is stored\n",
        "- `--seed SEED` the split seed\n",
        "- `--domain_alignment DOMAIN_1,DOMAIN_2,...DOMAIN_N PROP` the proportion for each domain group. This corresponds to what has been defined in `domain_proportion`\n",
        "\n",
        "When running this command, it will create a file containing the indices of the items available in the train set (update so that it matches what we set in the config file)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ea1d63eb-c931-484f-81da-58edfc090122",
      "metadata": {
        "id": "ea1d63eb-c931-484f-81da-58edfc090122"
      },
      "outputs": [],
      "source": [
        "# !shapesd alignment add --dataset_path \"simple_shapes_dataset\" --seed 0 --domain_alignment attr 1.0 --domain_alignment v 1.0 --domain_alignment attr,v 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "565b121c-f7a5-4bd3-a279-22616387b19a",
      "metadata": {
        "id": "565b121c-f7a5-4bd3-a279-22616387b19a"
      },
      "source": [
        "This time, we will load the config from the extra file `train_gw.yaml`\n",
        "\n",
        "First, let's update `main.yaml` to use the same alignment split:\n",
        "```yaml\n",
        "domain_proportions:\n",
        "    -   domains: [\"v\"]  # unimodal visual passes use 100% of the available data\n",
        "        proportion: 1.0\n",
        "    -   domains: [\"attr\"]  # unimodal attr passes use 100% of the available data\n",
        "        proportion: 1.0\n",
        "    -   domains: [\"v\", \"attr\"]  # paired passes uses 50% of the available data\n",
        "        proportion: 0.5\n",
        "```\n",
        "\n",
        "let's change the selected domains:\n",
        "\n",
        "```yaml\n",
        "domains:\n",
        "    - checkpoint_path: \"./checkpoints/visual/version_0/last.ckpt\"  # update to the actual version\n",
        "      domain_type: v_latents\n",
        "    - checkpoint_path: \"./checkpoints/attr/version_0/last.ckpt\"  # update to the actual version\n",
        "      domain_type: attr\n",
        "```\n",
        "\n",
        "and let's define the global workspace dimenison to 12:\n",
        "```yaml\n",
        "global_workspace:\n",
        "    latent_dim: 12  \n",
        "    \n",
        "    loss_coefficients:\n",
        "        cycles: 1.0\n",
        "        contrastives: 0.1\n",
        "        demi_cycles: 1.0\n",
        "        translations: 1.0\n",
        "\n",
        "    encoders:\n",
        "        hidden_dim: 32\n",
        "        n_layers: 3\n",
        "\n",
        "    decoders:\n",
        "        hidden_dim: 32\n",
        "        n_layers: 3\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb9d8076-115a-4182-bbb8-2599eb49feef",
      "metadata": {
        "id": "cb9d8076-115a-4182-bbb8-2599eb49feef"
      },
      "source": [
        "Finally, let's load the config:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0fde1645-60f5-445a-bb50-db1a97de23eb",
      "metadata": {
        "id": "0fde1645-60f5-445a-bb50-db1a97de23eb"
      },
      "outputs": [],
      "source": [
        "config = load_config(\"./config\", use_cli=False, load_files=[\"train_gw.yaml\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72288032-8119-47eb-8721-02490b88152d",
      "metadata": {
        "id": "72288032-8119-47eb-8721-02490b88152d"
      },
      "source": [
        "Skip the following cell if you have trained the unimodal module yourself. The next cell setups pretrained modules."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0eaa95a-8f85-4cbf-9c12-88911f720a7c",
      "metadata": {
        "id": "c0eaa95a-8f85-4cbf-9c12-88911f720a7c",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Run this if you did't train the modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "02e5f922-eb18-4713-a6b6-f2bbda61d5e5",
      "metadata": {
        "id": "02e5f922-eb18-4713-a6b6-f2bbda61d5e5",
        "outputId": "b756c600-dade-4f0b-f1db-8514d6afb90b"
      },
      "outputs": [],
      "source": [
        "# # Download checkpoints\n",
        "# !ssd download checkpoints\n",
        "# !mv checkpoints/checkpoints/* checkpoints/\n",
        "# !rm -rf checkpoints/checkpoints\n",
        "\n",
        "# # Extract visual latent from pretrained visual domain\n",
        "# !ssd extract v \"checkpoints/domain_v.ckpt\" -p \"simple_shapes_dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c21fe165-5f6c-470b-9a6e-ec17789a2799",
      "metadata": {
        "id": "c21fe165-5f6c-470b-9a6e-ec17789a2799"
      },
      "outputs": [],
      "source": [
        "# Update the config\n",
        "checkpoint_path = Path(\"./checkpoints\")\n",
        "config.domain_proportions = {\n",
        "    frozenset([\"v\"]): 1.0,\n",
        "    frozenset([\"attr\"]): 1.0,\n",
        "    frozenset([\"v\", \"attr\"]): 1.0,\n",
        "}\n",
        "\n",
        "config.domains = [\n",
        "    LoadedDomainConfig(\n",
        "        domain_type=DomainModuleVariant.v_latents,\n",
        "        checkpoint_path=checkpoint_path / \"domain_v.ckpt\",\n",
        "    ),\n",
        "    LoadedDomainConfig(\n",
        "        domain_type=DomainModuleVariant.attr_legacy,\n",
        "        checkpoint_path=checkpoint_path / \"domain_attr.ckpt\",\n",
        "        args={\"temperature\": .2, \"alpha\": 5},\n",
        "    ),\n",
        "]\n",
        "\n",
        "config.domain_data_args[\"v_latents\"][\"presaved_path\"] = \"domain_v.npy\"\n",
        "config.global_workspace.latent_dim = 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cc03a2e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import default_collate\n",
        "\n",
        "def custom_collate(batch):\n",
        "    result = default_collate(batch)\n",
        "    \n",
        "    # Check if we need to modify the second tensor in attr list\n",
        "    if (isinstance(result, dict) and \"attr\" in result and \n",
        "        isinstance(result[\"attr\"], list) and len(result[\"attr\"]) >= 2 and\n",
        "        isinstance(result[\"attr\"][1], torch.Tensor) and result[\"attr\"][1].size(-1) >= 4):\n",
        "        \n",
        "        # Remove the last 3 values from the tensor\n",
        "        result[\"attr\"][1] = result[\"attr\"][1][..., :-3]\n",
        "    \n",
        "    return result\n",
        "    \n",
        "domain_classes = get_default_domains([\"v_latents\", \"attr\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "fa6833da",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "data_module = SimpleShapesDataModule(\n",
        "    config.dataset.path,\n",
        "    domain_classes,\n",
        "    config.domain_proportions,\n",
        "    batch_size=config.training.batch_size,\n",
        "    num_workers=config.training.num_workers,\n",
        "    seed=config.seed,\n",
        "    domain_args=config.domain_data_args,\n",
        "    collate_fn=custom_collate  # utilisation du collate personnalisé\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14e86345-5644-4007-87fe-5f7a143f4d41",
      "metadata": {
        "id": "14e86345-5644-4007-87fe-5f7a143f4d41"
      },
      "source": [
        "### Load the domains and train\n",
        "We can now load the pretrained unimodal modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e1135c58-53b1-4c8f-9b76-373128d7f218",
      "metadata": {
        "id": "e1135c58-53b1-4c8f-9b76-373128d7f218"
      },
      "outputs": [],
      "source": [
        "# we load the pretrained domain modules and define the associated GW encoders and decoders\n",
        "domain_modules, gw_encoders, gw_decoders = load_pretrained_domains(\n",
        "    config.domains,\n",
        "    config.global_workspace.latent_dim,\n",
        "    config.global_workspace.encoders.hidden_dim,\n",
        "    config.global_workspace.encoders.n_layers,\n",
        "    config.global_workspace.decoders.hidden_dim,\n",
        "    config.global_workspace.decoders.n_layers,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebe7e3df-37c9-401b-a481-38609c18ceff",
      "metadata": {
        "id": "ebe7e3df-37c9-401b-a481-38609c18ceff"
      },
      "source": [
        "Instanciate the global Workspace class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3c26a008-3d9e-4676-bfb1-5364bbe8e752",
      "metadata": {
        "id": "3c26a008-3d9e-4676-bfb1-5364bbe8e752"
      },
      "outputs": [],
      "source": [
        "def get_scheduler(optimizer: Optimizer) -> OneCycleLR:\n",
        "    return OneCycleLR(optimizer, config.training.optim.max_lr, config.training.max_steps)\n",
        "\n",
        "\n",
        "global_workspace = GlobalWorkspace2Domains(\n",
        "    domain_modules,\n",
        "    gw_encoders,\n",
        "    gw_decoders,\n",
        "    config.global_workspace.latent_dim,\n",
        "    config.global_workspace.loss_coefficients,\n",
        "    config.training.optim.lr,\n",
        "    config.training.optim.weight_decay,\n",
        "    scheduler=get_scheduler,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcf92cee-a17a-4db2-960b-91e375235de5",
      "metadata": {
        "id": "fcf92cee-a17a-4db2-960b-91e375235de5"
      },
      "source": [
        "Add a Wandb logger to follow the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "145c0039-b27a-4ab3-a262-abb87a00d152",
      "metadata": {
        "id": "145c0039-b27a-4ab3-a262-abb87a00d152"
      },
      "outputs": [],
      "source": [
        "from lightning.pytorch.loggers.wandb import WandbLogger\n",
        "\n",
        "# logger = TensorBoardLogger(\"logs\", name=\"gw\")\n",
        "logger_wandb = WandbLogger(name=\"gw\", project=\"shimmer-ssd\")\n",
        "logger = logger_wandb\n",
        "# Get some image samples to log in tensorboard.\n",
        "train_samples = data_module.get_samples(\"train\", 32)\n",
        "val_samples = data_module.get_samples(\"val\", 32)\n",
        "\n",
        "# split the unique group in validation into individual groups for logging\n",
        "for domains in val_samples:\n",
        "    for domain in domains:\n",
        "        val_samples[frozenset([domain])] = {domain: val_samples[domains][domain]}\n",
        "    break\n",
        "# Create attr folder where we will save checkpoints\n",
        "(config.default_root_dir / \"gw\").mkdir(exist_ok=True)\n",
        "\n",
        "callbacks: list[Callback] = [\n",
        "    # Will log the validation ground-truth and reconstructions during training\n",
        "    LogGWImagesCallback(\n",
        "        val_samples,\n",
        "        log_key=\"images/val\",\n",
        "        mode=\"val\",\n",
        "        every_n_epochs=config.logging.log_val_medias_every_n_epochs,\n",
        "        filter=config.logging.filter_images,\n",
        "    ),\n",
        "    # Will log the training ground-truth and reconstructions during training\n",
        "    LogGWImagesCallback(\n",
        "        train_samples,\n",
        "        log_key=\"images/train\",\n",
        "        mode=\"train\",\n",
        "        every_n_epochs=config.logging.log_train_medias_every_n_epochs,\n",
        "        filter=config.logging.filter_images,\n",
        "    ),\n",
        "    # Save the checkpoints\n",
        "    ModelCheckpoint(\n",
        "        dirpath=config.default_root_dir / \"gw\" / f\"version_high_cycle{logger.version}\",\n",
        "        filename=\"{epoch}\",\n",
        "        monitor=\"val/loss\",\n",
        "        mode=\"min\",\n",
        "        save_last=\"link\",\n",
        "        save_top_k=1,\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59ae4778-9615-4415-abad-420787e66d2c",
      "metadata": {
        "id": "59ae4778-9615-4415-abad-420787e66d2c"
      },
      "source": [
        "For the final model, let's save where the model is saved:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b98b6642-ae5c-4cf8-9600-07882cd9d4ec",
      "metadata": {
        "id": "b98b6642-ae5c-4cf8-9600-07882cd9d4ec",
        "outputId": "30462a78-a1c8-4cb6-c259-f16fb1a6ae32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoints/gw/version_high_cycle_None/last.ckpt\n"
          ]
        }
      ],
      "source": [
        "gw_checkpoint = config.default_root_dir / \"gw\" / f\"version_high_cycle_{logger.version}\" / \"last.ckpt\"\n",
        "print(gw_checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82764468-75c4-4403-89e4-269ac0ae8779",
      "metadata": {
        "id": "82764468-75c4-4403-89e4-269ac0ae8779"
      },
      "source": [
        "And train!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf6de9e3-d4cd-4246-94df-4a677f8866b0",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "7907157ed2404360bf6613ae4ec30311",
            "cb1c358b657c455a858e60ece12ec8df",
            "ded8b395310e45e4af1c5c431ce9b690",
            "7090a88b7bef4a8eae426b6f75b40d53",
            "168c9a4c1b0947f380aa144870b73ff2",
            "7f6211c008094ca6a40317512fe61a2f",
            "ef158f26eeb64474b6e51ba63bfcaef1",
            "13e689c08e394397af715204465f59b6",
            "d962c807781f4395bd6bf2b8f347086d",
            "a0644a5109824e8e83c1ee8036ca514b",
            "52bc46a04be341ed8a0d15cc14bed750",
            "f6c05a13b84b46898ae335e20ee770d6",
            "60716e33b618458580f2598a2bc8c791",
            "344f12f6e53543fbb3387a6fb97d4050",
            "c133bbdc6a4e4beda39f3f8cc9da445c",
            "6db128282910453d9a4d2619c2735dfa",
            "e0155604002a4c6a82cd6a956cb69c32",
            "bf332f64b7e440d1879afdbe13ec541f",
            "9aae6d0b529e444dad67175751482134",
            "a868fc8fdf1046d99ed0e1bfe84972e2",
            "0bac39da29ef493aac4775a930660ae2",
            "2af3de4d9e2c4285878b446b3dc32712",
            "db30c0cbe8d14daebc8e4f0544dfb449",
            "9771ca8e88054908b1816f3e5b1239a6",
            "d6bc9b0e9f6a4b2f89993a1eb7c146a4",
            "cdb595c0656c4bc690871dc06593f042",
            "b51ee9eb61994ed1b9a21bdd22bc558a",
            "03cc2149c4cc41518ac143da639fbf46",
            "790313dd30b84f1f9bb64eaf6cac3332",
            "fb76922e4a2f4f5498a994f91ca9ac2e",
            "2109394bd6c54dd09d15193071b060e0",
            "b3d40700f5fd404397d5ae5f3062e67e",
            "73eeb98b5b824d84a839a8b900c44188",
            "8a7ac49f2ba3448e9e44217cd9750fb1",
            "525644d135df4a119f87afc7502ef1dd"
          ]
        },
        "id": "cf6de9e3-d4cd-4246-94df-4a677f8866b0",
        "outputId": "e18fabeb-56ab-4f6d-968b-5c505e8cef02",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlexman\u001b[0m (\u001b[33mlexman-psl\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>./wandb/run-20250325_145746-viq9fi6a</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/lexman-psl/Shimmer-SSD/runs/viq9fi6a' target=\"_blank\">gw</a></strong> to <a href='https://wandb.ai/lexman-psl/Shimmer-SSD' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/lexman-psl/Shimmer-SSD' target=\"_blank\">https://wandb.ai/lexman-psl/Shimmer-SSD</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/lexman-psl/Shimmer-SSD/runs/viq9fi6a' target=\"_blank\">https://wandb.ai/lexman-psl/Shimmer-SSD/runs/viq9fi6a</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
            "\n",
            "  | Name          | Type                  | Params | Mode \n",
            "----------------------------------------------------------------\n",
            "0 | gw_mod        | GWModule              | 5.9 M  | train\n",
            "1 | selection_mod | SingleDomainSelection | 0      | train\n",
            "2 | loss_mod      | GWLosses2Domains      | 5.9 M  | train\n",
            "----------------------------------------------------------------\n",
            "23.6 K    Trainable params\n",
            "5.8 M     Non-trainable params\n",
            "5.9 M     Total params\n",
            "23.411    Total estimated model params size (MB)\n",
            "28        Modules in train mode\n",
            "35        Modules in eval mode\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05a24ae19db346b3ae668ea29221b546",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c23667222f44b17b7c5987ef3ec025d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "512596a2ee464d47982b0b5c355e364d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "270aa044b0094e15b7fde57f90480768",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4653e9471d544f1d9005895c140da73c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df72391873044a2c823fb0b10a4fc1ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98d0686bbfdb48d68b0d4973a66b1a7d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e93c7b0139c4d27808ca9958ce09611",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3abf067efcc2497383225e26b8284aa7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bebcf128ae874cdb97b22346189c5189",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c9d545651604e0cae20eb1dc230212c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6bed83083af41dc95e7f10f9dc96a8c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ec5d9772ac849b4a968467461fc82cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11555b21c81b4010a26bec0d7b568365",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1665570fbabb4d9289283e23c268bdb6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b7308334b0e4959b399864901d61930",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2570b2575944f18a8a67b6ce436dfec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a431cc717764e858b0fcd18d3ec6044",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab98fb87037444a2bcf818a41620662a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "507a77c8977047db96a6031b6cefaac8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0615db8e78184f3db683a9e30061b893",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be45c488e1db432f9d8eca70e4d64f0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f15d38b8b944dfaa32049a64dc1cbb1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b42743aaa98848fa92a66f9c166b903c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a2a30693bb34dc094c118174ecba446",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84d375a33e93481992c39232ca5150d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0dc141aa680440dfb292a0bf867566dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1edf6bfabfb4c69bff2617fe3ae8592",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae7279b5ecb34abdbd9f194bba662300",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c61569e64be44c09407b0c3d5fdd1c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d06c94c04ba54b32a565a1b2c5080144",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7dae1da81ffe4ed6a9bf4da0492b389e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21ad5935caee4ee5873eaf8ee584f9a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36fd939d55ce4787b19d0c003d8bdbbc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc15c0d6485b41beacaf341563ed3424",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03e25f5367ce4713b6aea6872a96b567",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99a7d18e5ffa41df80d0801a5e49dda8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a236540e0dd8498ab846a24d12ddf3df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a5b606e940f4ea281a7404fa3b602ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e655d51f45fb42269fc7c1819aac589a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9edd97e939e348e0bae29b1e799b4580",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8fa5a769b9bb498d99ecccff5fd93b32",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ea6d22b3d9b45a2ae6dfc0db4262640",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63426aa5d2504b609b75179e2caa6962",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ccb9d60423c42e2bc6b6b1c08ef6c56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "186d80d5a75b48a39e26c09c76b37fe1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5eb4b083eb143a1836bcb09796e28a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d3c47b43b4e4732aacecf8dff4c2e28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b1cfda5e7864b149f534b1f1d7a6dea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a00606ca92942919a159637058969d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e2ccbb3ae734a5e9a0b8c24ec2b7583",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdb25a9f2db0432ab4e1a882a641159d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e18bd6d757448969bd248a6c74ae92a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df88ba06e4594d4f879f6d86bb450dde",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "919c300318164a479cbfc3d2b46797b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c41606e3727c4778a0b68e6024b1dae9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05528c2b176a478dbf29eb6e356cb449",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e87eff3eaf764520a7c45aa0bf2a88e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eaed84776e694c898e9fb745c12b7d23",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cbfdb88db294037bd0479488ccbf1ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6aa6e0f9c3d4a9b87c4c0f6ac310cdc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce7592d4dafd47c8afa7d439ebe918f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbdcbd44cbe2497dab4186931b1129d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "648a332b32f04f27a398f1a338256e2e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c993377ea17d4c3da7c6d06d6b8d8e04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b2384004c774dc5a92cba5f244dadcd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93218b3b0d1d444eaf333d34ddb8179a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa6206a6ab894abe9d9927f25b3c7378",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d40d84dfe4a945fab3943a44e357fe6b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d18ee7e3ed9e4b75a3c95ad0a0098149",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "588cf1c2a6c14118bb9a0c926ddf5803",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea41b20954c94b51bfbe73ef613e68b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c2c339108be48f084b53c85bebe6fda",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d8f3381f7504eb382091334e46762ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bde18737596a400c86ff9819ba99ce47",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6723a5d70f9b4b45bac0d869251001e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9967d99ae7f24df1b8f32de7adbcdb5b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e6c9253c4f94904b7bafedbb7331799",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfed62287cf24480b57604ce1df45ca3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6cf86a257874eccb9f71ef6752a828d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d49e3c33256d4732bb51e829cb5fb185",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d8a01f8f6f8447e8915b221beebc8cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "103ccda35b7d440fab3b304f401bad3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a6d5f13358944e2a151c06f6257844b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f172c8f60fe44a97bafd811244024157",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e90802fa0b7437d98c3b444cee1a370",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe81d30403e14b59834b1855a6bfdf29",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c88f0ec1382a44ce96dfb8923bc9277f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dda1f75fba4a4877ae07187667a5efce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa95e976199b4e1ebcdc02b7f06a2b12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b951cbd6e1349a18746c2b8b415c00f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b93c9b95aa9745a69fca9aac55f13344",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "803cef4bf171494db703180f8effb056",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf8b33786b4d4d21a825f08d58409ac2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "331080ee3f3d40eb8ae95babe7b35410",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1687097a84914acfa3962aac446439e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "037627c5870d48909fff6ef0450d423d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d842c17d3e1f4367a4b718cb4731dd53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d3a05e081d849108152c23d42483b17",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2de067e09e554f66a5ffc73ba484fbc7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e081dd2c0b9a4c3ca1a6ce8e029f65b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92f8411f6ad64aedbc3c59f69937897b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c3fd3098f6a4635b2d46bd30f5fcda8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c273e98ba294679a0938baf201d6dc5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21a1611c5a2a44b69418004ca5313d82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ede52dd8617464c840df0fbfea09e57",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e25258325c0e4f83917600c78e98984c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0cf6af56886b477aadf954e2ebb21083",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e369976b554f48cbb13e797eda592f66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82986d8b18ea4fe390d9d443907e4f35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2db3ea6081174db99357c27b6186352e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "323cb08913b640a681b26dff43fb5588",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e84b11c86fb44eeaeff6a4a19d013d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "886bd8f13a3042fdb7ad220a78f70045",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3fde842ab8094cfe9f7d50586c8030c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ace7dbdcb5f842109ad710fa0533a479",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "849312f3db874cec902fd9a6215db1f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c3abcaca0d84fd9972ce56afb754ae4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bab25c83534b4b1d8faf9186862a10d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n",
            "Shape of samples[1]: torch.Size([32, 8])\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    logger=logger,\n",
        "    max_steps=config.training.max_steps,\n",
        "    default_root_dir=config.default_root_dir,\n",
        "    callbacks=callbacks,\n",
        "    precision=config.training.precision,\n",
        "    accelerator=config.training.accelerator,\n",
        "    devices=config.training.devices,\n",
        ")\n",
        "\n",
        "trainer.fit(global_workspace, data_module)\n",
        "trainer.validate(global_workspace, data_module, \"best\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13117f0a",
      "metadata": {},
      "outputs": [],
      "source": [
        "#CEST UN TEST\n",
        "\n",
        "# Update the config\n",
        "checkpoint_path = Path(\"./checkpoints\")\n",
        "\n",
        "config.domain_proportions = {\n",
        "    frozenset([\"v\"]): 1.0,\n",
        "    frozenset([\"attr\"]): 1.0,\n",
        "    frozenset([\"v\", \"attr\"]): 1.0,\n",
        "}\n",
        "\n",
        "config.domains = [\n",
        "    LoadedDomainConfig(\n",
        "        domain_type=DomainModuleVariant.v_latents,\n",
        "        checkpoint_path=checkpoint_path / \"domain_v.ckpt\",\n",
        "    ),\n",
        "    LoadedDomainConfig(\n",
        "        domain_type=DomainModuleVariant.attr_legacy,\n",
        "        checkpoint_path=checkpoint_path / \"domain_attr.ckpt\",\n",
        "    ),\n",
        "]\n",
        "\n",
        "config.domain_data_args[\"v_latents\"][\"presaved_path\"] = \"domain_v.npy\"\n",
        "config.global_workspace.latent_dim = 12\n",
        "# And now we load the GW checkpoint\n",
        "checkpoint_path = Path(\"./checkpoints\")\n",
        "checkpoint = checkpoint_path / \"gw/version_None/epoch=660.ckpt\"\n",
        "# we load the pretrained domain modules and define the associated GW encoders and decoders\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1a30fb7",
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for GlobalWorkspace2Domains:\n\tMissing key(s) in state_dict: \"gw_mod.gw_decoders.attr.0.weight\", \"gw_mod.gw_decoders.attr.0.bias\", \"gw_mod.gw_decoders.attr.2.weight\", \"gw_mod.gw_decoders.attr.2.bias\", \"gw_mod.gw_decoders.attr.4.weight\", \"gw_mod.gw_decoders.attr.4.bias\", \"gw_mod.gw_decoders.attr.6.weight\", \"gw_mod.gw_decoders.attr.6.bias\", \"gw_mod.gw_decoders.attr.8.weight\", \"gw_mod.gw_decoders.attr.8.bias\", \"loss_mod.gw_mod.gw_decoders.attr.0.weight\", \"loss_mod.gw_mod.gw_decoders.attr.0.bias\", \"loss_mod.gw_mod.gw_decoders.attr.2.weight\", \"loss_mod.gw_mod.gw_decoders.attr.2.bias\", \"loss_mod.gw_mod.gw_decoders.attr.4.weight\", \"loss_mod.gw_mod.gw_decoders.attr.4.bias\", \"loss_mod.gw_mod.gw_decoders.attr.6.weight\", \"loss_mod.gw_mod.gw_decoders.attr.6.bias\", \"loss_mod.gw_mod.gw_decoders.attr.8.weight\", \"loss_mod.gw_mod.gw_decoders.attr.8.bias\". \n\tUnexpected key(s) in state_dict: \"gw_mod.gw_decoders.attr.decoder.0.weight\", \"gw_mod.gw_decoders.attr.decoder.0.bias\", \"gw_mod.gw_decoders.attr.decoder.2.weight\", \"gw_mod.gw_decoders.attr.decoder.2.bias\", \"gw_mod.gw_decoders.attr.decoder.4.weight\", \"gw_mod.gw_decoders.attr.decoder.4.bias\", \"gw_mod.gw_decoders.attr.decoder_categories.0.weight\", \"gw_mod.gw_decoders.attr.decoder_categories.0.bias\", \"gw_mod.gw_decoders.attr.decoder_attributes.0.weight\", \"gw_mod.gw_decoders.attr.decoder_attributes.0.bias\", \"loss_mod.gw_mod.gw_decoders.attr.decoder.0.weight\", \"loss_mod.gw_mod.gw_decoders.attr.decoder.0.bias\", \"loss_mod.gw_mod.gw_decoders.attr.decoder.2.weight\", \"loss_mod.gw_mod.gw_decoders.attr.decoder.2.bias\", \"loss_mod.gw_mod.gw_decoders.attr.decoder.4.weight\", \"loss_mod.gw_mod.gw_decoders.attr.decoder.4.bias\", \"loss_mod.gw_mod.gw_decoders.attr.decoder_categories.0.weight\", \"loss_mod.gw_mod.gw_decoders.attr.decoder_categories.0.bias\", \"loss_mod.gw_mod.gw_decoders.attr.decoder_attributes.0.weight\", \"loss_mod.gw_mod.gw_decoders.attr.decoder_attributes.0.bias\". ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m global_workspace \u001b[38;5;241m=\u001b[39m \u001b[43mGlobalWorkspace2Domains\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdomain_mods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdomain_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgw_encoders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgw_encoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgw_decoders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgw_decoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/.conda_local_no_color/lib/python3.11/site-packages/lightning/pytorch/utilities/model_helpers.py:125\u001b[0m, in \u001b[0;36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scripting:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe classmethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` cannot be called on an instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please call it on the class type and make sure the return value is used.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m     )\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/.conda_local_no_color/lib/python3.11/site-packages/lightning/pytorch/core/module.py:1581\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1499\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1500\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;124;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1579\u001b[0m \n\u001b[1;32m   1580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1581\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1587\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
            "File \u001b[0;32m~/Desktop/.conda_local_no_color/lib/python3.11/site-packages/lightning/pytorch/core/saving.py:91\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_state(\u001b[38;5;28mcls\u001b[39m, checkpoint, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pl\u001b[38;5;241m.\u001b[39mLightningModule):\n\u001b[0;32m---> 91\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state_dict:\n",
            "File \u001b[0;32m~/Desktop/.conda_local_no_color/lib/python3.11/site-packages/lightning/pytorch/core/saving.py:187\u001b[0m, in \u001b[0;36m_load_state\u001b[0;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[1;32m    184\u001b[0m     obj\u001b[38;5;241m.\u001b[39mon_load_checkpoint(checkpoint)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# load the state_dict on the model automatically\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strict:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m keys\u001b[38;5;241m.\u001b[39mmissing_keys:\n",
            "File \u001b[0;32m~/Desktop/.conda_local_no_color/lib/python3.11/site-packages/torch/nn/modules/module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2576\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2577\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2579\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2580\u001b[0m             ),\n\u001b[1;32m   2581\u001b[0m         )\n\u001b[1;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2587\u001b[0m         )\n\u001b[1;32m   2588\u001b[0m     )\n\u001b[1;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GlobalWorkspace2Domains:\n\tMissing key(s) in state_dict: \"gw_mod.gw_decoders.attr.0.weight\", \"gw_mod.gw_decoders.attr.0.bias\", \"gw_mod.gw_decoders.attr.2.weight\", \"gw_mod.gw_decoders.attr.2.bias\", \"gw_mod.gw_decoders.attr.4.weight\", \"gw_mod.gw_decoders.attr.4.bias\", \"gw_mod.gw_decoders.attr.6.weight\", \"gw_mod.gw_decoders.attr.6.bias\", \"gw_mod.gw_decoders.attr.8.weight\", \"gw_mod.gw_decoders.attr.8.bias\", \"loss_mod.gw_mod.gw_decoders.attr.0.weight\", \"loss_mod.gw_mod.gw_decoders.attr.0.bias\", \"loss_mod.gw_mod.gw_decoders.attr.2.weight\", \"loss_mod.gw_mod.gw_decoders.attr.2.bias\", \"loss_mod.gw_mod.gw_decoders.attr.4.weight\", \"loss_mod.gw_mod.gw_decoders.attr.4.bias\", \"loss_mod.gw_mod.gw_decoders.attr.6.weight\", \"loss_mod.gw_mod.gw_decoders.attr.6.bias\", \"loss_mod.gw_mod.gw_decoders.attr.8.weight\", \"loss_mod.gw_mod.gw_decoders.attr.8.bias\". \n\tUnexpected key(s) in state_dict: \"gw_mod.gw_decoders.attr.decoder.0.weight\", \"gw_mod.gw_decoders.attr.decoder.0.bias\", \"gw_mod.gw_decoders.attr.decoder.2.weight\", \"gw_mod.gw_decoders.attr.decoder.2.bias\", \"gw_mod.gw_decoders.attr.decoder.4.weight\", \"gw_mod.gw_decoders.attr.decoder.4.bias\", \"gw_mod.gw_decoders.attr.decoder_categories.0.weight\", \"gw_mod.gw_decoders.attr.decoder_categories.0.bias\", \"gw_mod.gw_decoders.attr.decoder_attributes.0.weight\", \"gw_mod.gw_decoders.attr.decoder_attributes.0.bias\", \"loss_mod.gw_mod.gw_decoders.attr.decoder.0.weight\", \"loss_mod.gw_mod.gw_decoders.attr.decoder.0.bias\", \"loss_mod.gw_mod.gw_decoders.attr.decoder.2.weight\", \"loss_mod.gw_mod.gw_decoders.attr.decoder.2.bias\", \"loss_mod.gw_mod.gw_decoders.attr.decoder.4.weight\", \"loss_mod.gw_mod.gw_decoders.attr.decoder.4.bias\", \"loss_mod.gw_mod.gw_decoders.attr.decoder_categories.0.weight\", \"loss_mod.gw_mod.gw_decoders.attr.decoder_categories.0.bias\", \"loss_mod.gw_mod.gw_decoders.attr.decoder_attributes.0.weight\", \"loss_mod.gw_mod.gw_decoders.attr.decoder_attributes.0.bias\". "
          ]
        }
      ],
      "source": [
        "global_workspace = GlobalWorkspace2Domains.load_from_checkpoint(\n",
        "    checkpoint,\n",
        "    domain_mods=domain_modules,\n",
        "    gw_encoders=gw_encoders,\n",
        "    gw_decoders=gw_decoders,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f99d2f8-e3d4-4e42-bda0-bc949bf1d248",
      "metadata": {
        "id": "4f99d2f8-e3d4-4e42-bda0-bc949bf1d248",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Run this if you did't train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baeef54d-ab50-490d-931b-8fa8d71e9026",
      "metadata": {
        "id": "baeef54d-ab50-490d-931b-8fa8d71e9026"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for GlobalWorkspace2Domains:\n\tMissing key(s) in state_dict: \"gw_mod.gw_decoders.attr.0.weight\", \"gw_mod.gw_decoders.attr.0.bias\", \"gw_mod.gw_decoders.attr.2.weight\", \"gw_mod.gw_decoders.attr.2.bias\", \"gw_mod.gw_decoders.attr.4.weight\", \"gw_mod.gw_decoders.attr.4.bias\", \"gw_mod.gw_decoders.attr.6.weight\", \"gw_mod.gw_decoders.attr.6.bias\", \"gw_mod.gw_decoders.attr.8.weight\", \"gw_mod.gw_decoders.attr.8.bias\", \"loss_mod.gw_mod.gw_decoders.attr.0.weight\", \"loss_mod.gw_mod.gw_decoders.attr.0.bias\", \"loss_mod.gw_mod.gw_decoders.attr.2.weight\", \"loss_mod.gw_mod.gw_decoders.attr.2.bias\", \"loss_mod.gw_mod.gw_decoders.attr.4.weight\", \"loss_mod.gw_mod.gw_decoders.attr.4.bias\", \"loss_mod.gw_mod.gw_decoders.attr.6.weight\", \"loss_mod.gw_mod.gw_decoders.attr.6.bias\", \"loss_mod.gw_mod.gw_decoders.attr.8.weight\", \"loss_mod.gw_mod.gw_decoders.attr.8.bias\". \n\tUnexpected key(s) in state_dict: \"gw_mod.gw_decoders.attr.decoder.0.weight\", \"gw_mod.gw_decoders.attr.decoder.0.bias\", \"gw_mod.gw_decoders.attr.decoder.2.weight\", \"gw_mod.gw_decoders.attr.decoder.2.bias\", \"gw_mod.gw_decoders.attr.decoder.4.weight\", \"gw_mod.gw_decoders.attr.decoder.4.bias\", \"gw_mod.gw_decoders.attr.decoder_categories.0.weight\", \"gw_mod.gw_decoders.attr.decoder_categories.0.bias\", \"gw_mod.gw_decoders.attr.decoder_attributes.0.weight\", \"gw_mod.gw_decoders.attr.decoder_attributes.0.bias\", \"loss_mod.gw_mod.gw_decoders.attr.decoder.0.weight\", \"loss_mod.gw_mod.gw_decoders.attr.decoder.0.bias\", \"loss_mod.gw_mod.gw_decoders.attr.decoder.2.weight\", \"loss_mod.gw_mod.gw_decoders.attr.decoder.2.bias\", \"loss_mod.gw_mod.gw_decoders.attr.decoder.4.weight\", \"loss_mod.gw_mod.gw_decoders.attr.decoder.4.bias\", \"loss_mod.gw_mod.gw_decoders.attr.decoder_categories.0.weight\", \"loss_mod.gw_mod.gw_decoders.attr.decoder_categories.0.bias\", \"loss_mod.gw_mod.gw_decoders.attr.decoder_attributes.0.weight\", \"loss_mod.gw_mod.gw_decoders.attr.decoder_attributes.0.bias\". ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 36\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# checkpoint = checkpoint_path / \"gw-attr-v-half-paired-data.ckpt\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# we load the pretrained domain modules and define the associated GW encoders and decoders\u001b[39;00m\n\u001b[1;32m     27\u001b[0m domain_modules, gw_encoders, gw_decoders \u001b[38;5;241m=\u001b[39m load_pretrained_domains(\n\u001b[1;32m     28\u001b[0m     config\u001b[38;5;241m.\u001b[39mdomains,\n\u001b[1;32m     29\u001b[0m     config\u001b[38;5;241m.\u001b[39mglobal_workspace\u001b[38;5;241m.\u001b[39mlatent_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     config\u001b[38;5;241m.\u001b[39mglobal_workspace\u001b[38;5;241m.\u001b[39mdecoders\u001b[38;5;241m.\u001b[39mn_layers,\n\u001b[1;32m     34\u001b[0m )\n\u001b[0;32m---> 36\u001b[0m global_workspace \u001b[38;5;241m=\u001b[39m \u001b[43mGlobalWorkspace2Domains\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdomain_mods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdomain_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgw_encoders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgw_encoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgw_decoders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgw_decoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/.conda_local_no_color/lib/python3.11/site-packages/lightning/pytorch/utilities/model_helpers.py:125\u001b[0m, in \u001b[0;36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scripting:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe classmethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` cannot be called on an instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please call it on the class type and make sure the return value is used.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m     )\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/.conda_local_no_color/lib/python3.11/site-packages/lightning/pytorch/core/module.py:1581\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1499\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1500\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;124;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1579\u001b[0m \n\u001b[1;32m   1580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1581\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1587\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
            "File \u001b[0;32m~/Desktop/.conda_local_no_color/lib/python3.11/site-packages/lightning/pytorch/core/saving.py:91\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_state(\u001b[38;5;28mcls\u001b[39m, checkpoint, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pl\u001b[38;5;241m.\u001b[39mLightningModule):\n\u001b[0;32m---> 91\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state_dict:\n",
            "File \u001b[0;32m~/Desktop/.conda_local_no_color/lib/python3.11/site-packages/lightning/pytorch/core/saving.py:187\u001b[0m, in \u001b[0;36m_load_state\u001b[0;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[1;32m    184\u001b[0m     obj\u001b[38;5;241m.\u001b[39mon_load_checkpoint(checkpoint)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# load the state_dict on the model automatically\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strict:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m keys\u001b[38;5;241m.\u001b[39mmissing_keys:\n",
            "File \u001b[0;32m~/Desktop/.conda_local_no_color/lib/python3.11/site-packages/torch/nn/modules/module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2576\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2577\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2579\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2580\u001b[0m             ),\n\u001b[1;32m   2581\u001b[0m         )\n\u001b[1;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2587\u001b[0m         )\n\u001b[1;32m   2588\u001b[0m     )\n\u001b[1;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GlobalWorkspace2Domains:\n\tMissing key(s) in state_dict: \"gw_mod.gw_decoders.attr.0.weight\", \"gw_mod.gw_decoders.attr.0.bias\", \"gw_mod.gw_decoders.attr.2.weight\", \"gw_mod.gw_decoders.attr.2.bias\", \"gw_mod.gw_decoders.attr.4.weight\", \"gw_mod.gw_decoders.attr.4.bias\", \"gw_mod.gw_decoders.attr.6.weight\", \"gw_mod.gw_decoders.attr.6.bias\", \"gw_mod.gw_decoders.attr.8.weight\", \"gw_mod.gw_decoders.attr.8.bias\", \"loss_mod.gw_mod.gw_decoders.attr.0.weight\", \"loss_mod.gw_mod.gw_decoders.attr.0.bias\", \"loss_mod.gw_mod.gw_decoders.attr.2.weight\", \"loss_mod.gw_mod.gw_decoders.attr.2.bias\", \"loss_mod.gw_mod.gw_decoders.attr.4.weight\", \"loss_mod.gw_mod.gw_decoders.attr.4.bias\", \"loss_mod.gw_mod.gw_decoders.attr.6.weight\", \"loss_mod.gw_mod.gw_decoders.attr.6.bias\", \"loss_mod.gw_mod.gw_decoders.attr.8.weight\", \"loss_mod.gw_mod.gw_decoders.attr.8.bias\". \n\tUnexpected key(s) in state_dict: \"gw_mod.gw_decoders.attr.decoder.0.weight\", \"gw_mod.gw_decoders.attr.decoder.0.bias\", \"gw_mod.gw_decoders.attr.decoder.2.weight\", \"gw_mod.gw_decoders.attr.decoder.2.bias\", \"gw_mod.gw_decoders.attr.decoder.4.weight\", \"gw_mod.gw_decoders.attr.decoder.4.bias\", \"gw_mod.gw_decoders.attr.decoder_categories.0.weight\", \"gw_mod.gw_decoders.attr.decoder_categories.0.bias\", \"gw_mod.gw_decoders.attr.decoder_attributes.0.weight\", \"gw_mod.gw_decoders.attr.decoder_attributes.0.bias\", \"loss_mod.gw_mod.gw_decoders.attr.decoder.0.weight\", \"loss_mod.gw_mod.gw_decoders.attr.decoder.0.bias\", \"loss_mod.gw_mod.gw_decoders.attr.decoder.2.weight\", \"loss_mod.gw_mod.gw_decoders.attr.decoder.2.bias\", \"loss_mod.gw_mod.gw_decoders.attr.decoder.4.weight\", \"loss_mod.gw_mod.gw_decoders.attr.decoder.4.bias\", \"loss_mod.gw_mod.gw_decoders.attr.decoder_categories.0.weight\", \"loss_mod.gw_mod.gw_decoders.attr.decoder_categories.0.bias\", \"loss_mod.gw_mod.gw_decoders.attr.decoder_attributes.0.weight\", \"loss_mod.gw_mod.gw_decoders.attr.decoder_attributes.0.bias\". "
          ]
        }
      ],
      "source": [
        "# Update the config\n",
        "checkpoint_path = Path(\"./checkpoints\")\n",
        "\n",
        "config.domain_proportions = {\n",
        "    frozenset([\"v\"]): 1.0,\n",
        "    frozenset([\"attr\"]): 1.0,\n",
        "    frozenset([\"v\", \"attr\"]): 1.0,\n",
        "}\n",
        "\n",
        "config.domains = [\n",
        "    LoadedDomainConfig(\n",
        "        domain_type=DomainModuleVariant.v_latents,\n",
        "        checkpoint_path=checkpoint_path / \"domain_v.ckpt\",\n",
        "    ),\n",
        "    LoadedDomainConfig(\n",
        "        domain_type=DomainModuleVariant.attr_legacy,\n",
        "        checkpoint_path=checkpoint_path / \"domain_attr.ckpt\",\n",
        "    ),\n",
        "]\n",
        "\n",
        "config.domain_data_args[\"v_latents\"][\"presaved_path\"] = \"domain_v.npy\"\n",
        "config.global_workspace.latent_dim = 12\n",
        "# And now we load the GW checkpoint\n",
        "checkpoint_path = Path(\"./checkpoints\")\n",
        "# checkpoint = checkpoint_path / \"gw-attr-v-half-paired-data.ckpt\"\n",
        "# we load the pretrained domain modules and define the associated GW encoders and decoders\n",
        "domain_modules, gw_encoders, gw_decoders = load_pretrained_domains(\n",
        "    config.domains,\n",
        "    config.global_workspace.latent_dim,\n",
        "    config.global_workspace.encoders.hidden_dim,\n",
        "    config.global_workspace.encoders.n_layers,\n",
        "    config.global_workspace.decoders.hidden_dim,\n",
        "    config.global_workspace.decoders.n_layers,\n",
        ")\n",
        "\n",
        "global_workspace = GlobalWorkspace2Domains.load_from_checkpoint(\n",
        "    checkpoint,\n",
        "    domain_mods=domain_modules,\n",
        "    gw_encoders=gw_encoders,\n",
        "    gw_decoders=gw_decoders,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aefbfff6-8cbc-4a72-8e34-47c2d28f0e6d",
      "metadata": {
        "id": "aefbfff6-8cbc-4a72-8e34-47c2d28f0e6d"
      },
      "source": [
        "## Play with the global workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0cc65be-5456-4f3a-8216-0d061deec60e",
      "metadata": {
        "id": "e0cc65be-5456-4f3a-8216-0d061deec60e"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import math\n",
        "# %pip install ipywidgets ipympl\n",
        "import ipywidgets as widgets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from ipywidgets import interact, interact_manual\n",
        "from PIL import Image\n",
        "from shimmer_ssd.logging import attribute_image_grid\n",
        "from torch.nn.functional import one_hot\n",
        "\n",
        "from simple_shapes_dataset.cli import generate_image\n",
        "%matplotlib widget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81b9ab47",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !conda install -c conda-forge ipympl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b204af9d-df27-4462-9dfc-b45d8e7eb3d5",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "d4f37e3214cb4738951b5144b9192720"
          ]
        },
        "id": "b204af9d-df27-4462-9dfc-b45d8e7eb3d5",
        "outputId": "e01d7a19-5210-4375-c399-fa20accbc5b8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c88d0d286e64de8bfc84a416dc31574",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(Dropdown(description='cat', options=('Triangle', 'Egg', 'Diamond'), value='Triangle'), F…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "global_workspace.to(device)\n",
        "\n",
        "cat2idx = {\"Diamond\": 0, \"Egg\": 1, \"Triangle\": 2}\n",
        "\n",
        "\n",
        "def get_image(cat, x, y, size, rot, color_r, color_g, color_b):\n",
        "    fig, ax = plt.subplots(figsize=(32, 32), dpi=1)\n",
        "    # The dataset generatoion tool has function to generate a matplotlib shape\n",
        "    # from the attributes.\n",
        "    generate_image(\n",
        "        ax,\n",
        "        cat2idx[cat],\n",
        "        [int(x * 18 + 7), int(y * 18 + 7)],\n",
        "        size * 7 + 7,\n",
        "        rot * 2 * math.pi,\n",
        "        np.array([color_r * 255, color_g * 255, color_b * 255]),\n",
        "        imsize=32,\n",
        "    )\n",
        "    ax.set_facecolor(\"black\")\n",
        "    plt.tight_layout(pad=0)\n",
        "    # Return this as a PIL Image.\n",
        "    # This is to have the same dpi as saved images\n",
        "    # otherwise matplotlib will render this in very high quality\n",
        "    buf = io.BytesIO()\n",
        "    fig.savefig(buf)\n",
        "    buf.seek(0)\n",
        "    image = Image.open(buf)\n",
        "    plt.close(fig)\n",
        "    return image\n",
        "\n",
        "\n",
        "@interact(\n",
        "    cat=[\"Triangle\", \"Egg\", \"Diamond\"],\n",
        "    x=(0, 1, 0.1),\n",
        "    y=(0, 1, 0.1),\n",
        "    rot=(0, 1, 0.1),\n",
        "    size=(0, 1, 0.1),\n",
        "    color_r=(0, 1, 0.1),\n",
        "    color_g=(0, 1, 0.1),\n",
        "    color_b=(0, 1, 0.1),\n",
        ")\n",
        "def play_with_gw(\n",
        "    cat: str = \"Triangle\",\n",
        "    x: float = 0.5,\n",
        "    y: float = 0.5,\n",
        "    rot: float = 0.5,\n",
        "    size: float = 0.5,\n",
        "    color_r: float = 1,\n",
        "    color_g: float = 0,\n",
        "    color_b: float = 0,\n",
        "):\n",
        "    fig, axes = plt.subplots(1, 2)\n",
        "    image = get_image(cat, x, y, size, rot, color_r, color_g, color_b)\n",
        "    axes[0].set_facecolor(\"black\")\n",
        "    axes[0].set_title(\"Original image from attributes\")\n",
        "    axes[0].set_xticks([])\n",
        "    axes[0].set_yticks([])\n",
        "    axes[0].imshow(image)\n",
        "\n",
        "    # normalize the attribute for the global workspace.\n",
        "    category = one_hot(torch.tensor([cat2idx[cat]]), 3)\n",
        "    rotx = math.cos(rot * 2 * math.pi)\n",
        "    roty = math.sin(rot * 2 * math.pi)\n",
        "    \n",
        "    attributes = torch.tensor(\n",
        "        [[x * 2 - 1, y * 2 - 1, size * 2 - 1, rotx, roty]]  # , color_r * 2 - 1, color_g * 2 - 1, color_b * 2 - 1]]\n",
        "    )\n",
        "    samples = [category.to(device), attributes.to(device)]\n",
        "    attr_gw_latent = global_workspace.gw_mod.encode({\"attr\": global_workspace.encode_domain(samples, \"attr\")})\n",
        "    gw_latent = global_workspace.gw_mod.fuse(\n",
        "        attr_gw_latent, {\"attr\": torch.ones(attr_gw_latent[\"attr\"].size(0)).to(device)}\n",
        "    )\n",
        "    decoded_latents = global_workspace.gw_mod.decode(gw_latent)[\"v_latents\"]\n",
        "    decoded_images = (\n",
        "        global_workspace.domain_mods[\"v_latents\"]\n",
        "        .decode_images(decoded_latents)[0]\n",
        "        .permute(1, 2, 0)\n",
        "        .detach()\n",
        "        .cpu()\n",
        "        .numpy()\n",
        "    )\n",
        "    axes[1].imshow(decoded_images)\n",
        "    axes[1].set_xticks([])\n",
        "    axes[1].set_yticks([])\n",
        "    axes[1].set_title(\"Translated image through GW\")\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
