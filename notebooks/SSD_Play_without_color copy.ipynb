{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --force-reinstall \"git+https://github.com/AEmanuelli/shimmer-ssd.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from shimmer.modules.domain import DomainModule\n",
    "from shimmer.modules.global_workspace import GlobalWorkspace2Domains, SchedulerArgs\n",
    "\n",
    "from shimmer_ssd.config import DomainModuleVariant, LoadedDomainConfig, load_config\n",
    "\n",
    "from shimmer_ssd.modules.domains import load_pretrained_domains\n",
    "\n",
    "from simple_shapes_dataset import SimpleShapesDataModule, get_default_domains\n",
    "\n",
    "\n",
    "# %matplotlib inlineKikabosco2\n",
    "\n",
    "import io\n",
    "import math\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from ipywidgets import interact, interact_manual\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from shimmer_ssd.logging import attribute_image_grid\n",
    "from shimmer_ssd.config import load_config\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "from simple_shapes_dataset.cli import generate_image\n",
    "%matplotlib widget\n",
    "\n",
    "# And now we load the GW checkpoint\n",
    "checkpoint_path = Path(\"/mnt/HD2/alexis_data/checkpoints_backup/checkpoints\")\n",
    "\n",
    "# We don't use cli in the notebook, but consider using it in normal scripts.\n",
    "config = load_config(\"./config\", use_cli=False)\n",
    "\n",
    "config.domain_proportions = {\n",
    "    frozenset([\"v\"]): 1.0,\n",
    "    frozenset([\"attr\"]): 1.0,\n",
    "    frozenset([\"v\", \"attr\"]): 1.0,\n",
    "}\n",
    "\n",
    "config.domains = [\n",
    "    LoadedDomainConfig(\n",
    "        domain_type=DomainModuleVariant.v_latents,\n",
    "        checkpoint_path=checkpoint_path / \"domain_v.ckpt\",\n",
    "    ),\n",
    "    LoadedDomainConfig(\n",
    "        domain_type=DomainModuleVariant.attr_legacy_no_color,\n",
    "        checkpoint_path=checkpoint_path / \"domain_attr.ckpt\",\n",
    "        args = {\"alpha\": 1, \"temperature\": 1},\n",
    "    ),\n",
    "]\n",
    "\n",
    "config.domain_data_args[\"v_latents\"][\"presaved_path\"] = \"domain_v.npy\"\n",
    "config.global_workspace.latent_dim = 12\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import io\n",
    "from PIL import Image\n",
    "from torch.nn.functional import one_hot\n",
    "from ipywidgets import interact\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# checkpoint = \"/home/alexis/Desktop/checkpoints/training_logs/Removing_colors/High alpha 5 (color) - corrected v5 (Logsoftmax --> exp --> log)/checkpoints/last.ckpt\"\n",
    "# checkpoint = \"/home/alexis/Desktop/checkpoints/training_logs/Removing_colors/Base_params - corrected v5 (Logsoftmax --> exp --> log)/checkpoints/last.ckpt\"\n",
    "\n",
    "# checkpoint = \"/home/alexis/Desktop/checkpoints/training_logs/Removing_colors/(Seed 0) High_cycles (10) v5/checkpoints/last.ckpt\"\n",
    "checkpoint = \"/home/alexis/Desktop/checkpoints/training_logs/Removing_colors/(Seed 0) High_cycles (10) v5/checkpoints/last.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# config.global_workspace.encoders.hidden_dim = 256\n",
    "# config.global_workspace.encoders.n_layers = 2\n",
    "# config.global_workspace.decoders.hidden_dim = 256\n",
    "# config.global_workspace.decoders.n_layers = 2\n",
    "# # we load the pretrained domain modules and define the associated GW encoders and decoders\n",
    "# domain_modules, gw_encoders, gw_decoders = load_pretrained_domains(\n",
    "#     config.domains,\n",
    "#     config.global_workspace.latent_dim,\n",
    "#     config.global_workspace.encoders.hidden_dim,\n",
    "#     config.global_workspace.encoders.n_layers,\n",
    "#     config.global_workspace.decoders.hidden_dim,\n",
    "#     config.global_workspace.decoders.n_layers,\n",
    "# )\n",
    "# global_workspace = GlobalWorkspace2Domains.load_from_checkpoint(\n",
    "#     checkpoint,\n",
    "#     domain_mods=domain_modules,\n",
    "#     gw_encoders=gw_encoders,\n",
    "#     gw_decoders=gw_decoders,\n",
    "# )\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# global_workspace.to(device)\n",
    "\n",
    "# cat2idx = {\"Diamond\": 0, \"Egg\": 1, \"Triangle\": 2}\n",
    "# categories = [\"Diamond\", \"Egg\", \"Triangle\"]\n",
    "\n",
    "# def normalize_cat_values(diamond, egg, triangle):\n",
    "#     \"\"\"Normalise les valeurs de catégories pour qu'elles somment à 1\"\"\"\n",
    "#     values = torch.tensor([diamond, egg, triangle], dtype=torch.float32)\n",
    "#     # Appliquer softmax pour garantir que les valeurs sont positives et somment à 1\n",
    "#     return values\n",
    "\n",
    "# def get_dominant_category(cat_values):\n",
    "#     \"\"\"Retourne la catégorie dominante pour la visualisation\"\"\"\n",
    "#     cat_idx = torch.argmax(cat_values).item()\n",
    "#     return categories[cat_idx]\n",
    "\n",
    "# def get_image(cat_values, x, y, size, rot, color_r, color_g, color_b):\n",
    "#     \"\"\"Génère une image basée sur la catégorie dominante\"\"\"\n",
    "#     # Obtenir la catégorie avec la valeur la plus élevée\n",
    "#     cat_idx = torch.argmax(cat_values).item()\n",
    "#     cat = categories[cat_idx]\n",
    "    \n",
    "#     # Générer l'image pour cette catégorie\n",
    "#     fig, ax = plt.subplots(figsize=(32, 32), dpi=1)\n",
    "#     generate_image(\n",
    "#         ax,\n",
    "#         cat2idx[cat],\n",
    "#         [int(x * 18 + 7), int(y * 18 + 7)],\n",
    "#         size * 7 + 7,\n",
    "#         rot * 2 * math.pi,\n",
    "#         np.array([color_r * 255, color_g * 255, color_b * 255]),\n",
    "#         imsize=32,\n",
    "#     )\n",
    "#     ax.set_facecolor(\"black\")\n",
    "#     plt.tight_layout(pad=0)\n",
    "    \n",
    "#     # Retourner l'image\n",
    "#     buf = io.BytesIO()\n",
    "#     fig.savefig(buf)\n",
    "#     buf.seek(0)\n",
    "#     image = Image.open(buf)\n",
    "#     plt.close(fig)\n",
    "#     return image\n",
    "\n",
    "# @interact(\n",
    "#     diamond=(0.0001, 1, 0.00001),\n",
    "#     egg=(0.0001, 1, 0.00001),\n",
    "#     triangle=(0, 1, 0.00001),\n",
    "#     x=(0, 1, 0.01),\n",
    "#     y=(0, 1, 0.01),\n",
    "#     rot=(0, 1, 0.01),\n",
    "#     size=(0, 1, 0.01),\n",
    "#     color_r=(0, 1, 0.01),\n",
    "#     color_g=(0, 1, 0.01),\n",
    "#     color_b=(0, 1, 0.01),\n",
    "# )\n",
    "# def play_with_gw(\n",
    "#     diamond: float = 0.0,\n",
    "#     egg: float = 0.0,\n",
    "#     triangle: float = 1.0,\n",
    "#     x: float = 0.5,\n",
    "#     y: float = 0.5,\n",
    "#     rot: float = 0.5,\n",
    "#     size: float = 0.5,\n",
    "#     color_r: float = 1,\n",
    "#     color_g: float = 0,\n",
    "#     color_b: float = 0,\n",
    "# ):\n",
    "#     # Normaliser les valeurs de catégories\n",
    "#     cat_values = normalize_cat_values(diamond, egg, triangle)\n",
    "#     dominant_cat = get_dominant_category(cat_values)\n",
    "    \n",
    "#     fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "#     # Image originale basée sur la catégorie dominante\n",
    "#     image = get_image(cat_values, x, y, size, rot, color_r, color_g, color_b)\n",
    "#     axes[0].set_facecolor(\"black\")\n",
    "#     axes[0].set_title(f\"Image originale\\nCatégorie dominante: {dominant_cat}\")\n",
    "#     axes[0].set_xticks([])\n",
    "#     axes[0].set_yticks([])\n",
    "#     axes[0].imshow(image)\n",
    "    \n",
    "#     # Visualisation des valeurs de catégories\n",
    "#     axes[1].bar(categories, cat_values.numpy())\n",
    "#     axes[1].set_title(\"Distribution des catégories\")\n",
    "#     axes[1].set_ylim(0, 1)\n",
    "    \n",
    "#     # Préparer les attributs pour le global workspace\n",
    "#     rotx = math.cos(rot * 2 * math.pi)\n",
    "#     roty = math.sin(rot * 2 * math.pi)\n",
    "#     attributes = torch.tensor(\n",
    "#         [[x * 2 - 1, y * 2 - 1, size * 2 - 1, rotx, roty]]\n",
    "#     )\n",
    "    \n",
    "#     # Exécuter le modèle\n",
    "#     # Utiliser directement le tenseur cat_values au lieu de one_hot encoding\n",
    "#     category = cat_values.unsqueeze(0)  # Ajouter dimension batch\n",
    "    \n",
    "#     samples = [category.to(device), attributes.to(device)]\n",
    "#     attr_gw_latent = global_workspace.gw_mod.encode({\"attr\": global_workspace.encode_domain(samples, \"attr\")})\n",
    "#     gw_latent = global_workspace.gw_mod.fuse(\n",
    "#         attr_gw_latent, {\"attr\": torch.ones(attr_gw_latent[\"attr\"].size(0)).to(device)}\n",
    "#     )\n",
    "#     decoded_latents = global_workspace.gw_mod.decode(gw_latent)[\"v_latents\"]\n",
    "#     decoded_images = (\n",
    "#         global_workspace.domain_mods[\"v_latents\"]\n",
    "#         .decode_images(decoded_latents)[0]\n",
    "#         .permute(1, 2, 0)\n",
    "#         .detach()\n",
    "#         .cpu()\n",
    "#         .numpy()\n",
    "#     )\n",
    "    \n",
    "#     # Afficher l'image générée\n",
    "#     axes[2].imshow(decoded_images)\n",
    "#     axes[2].set_xticks([])\n",
    "#     axes[2].set_yticks([])\n",
    "#     axes[2].set_title(\"Image traduite via GW\")\n",
    "    \n",
    "#     # Afficher les valeurs exactes\n",
    "#     print(f\"Valeurs normalisées: Diamond={cat_values[0]:.4f}, Egg={cat_values[1]:.4f}, Triangle={cat_values[2]:.4f}\")\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default alpha and temperature are loaded (1, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ad67fe8d6b4ce6a3eaa3b5759c59c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='cat', options=('Triangle', 'Egg', 'Diamond'), value='Triangle'), F…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config.global_workspace.encoders.hidden_dim = 256\n",
    "config.global_workspace.encoders.n_layers = 2\n",
    "config.global_workspace.decoders.hidden_dim = 256\n",
    "config.global_workspace.decoders.n_layers = 2\n",
    "# we load the pretrained domain modules and define the associated GW encoders and decoders\n",
    "domain_modules, gw_encoders, gw_decoders = load_pretrained_domains(\n",
    "    config.domains,\n",
    "    config.global_workspace.latent_dim,\n",
    "    config.global_workspace.encoders.hidden_dim,\n",
    "    config.global_workspace.encoders.n_layers,\n",
    "    config.global_workspace.decoders.hidden_dim,\n",
    "    config.global_workspace.decoders.n_layers,\n",
    ")\n",
    "global_workspace = GlobalWorkspace2Domains.load_from_checkpoint(\n",
    "    checkpoint,\n",
    "    domain_mods=domain_modules,\n",
    "    gw_encoders=gw_encoders,\n",
    "    gw_decoders=gw_decoders,\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "global_workspace.to(device)\n",
    "\n",
    "\n",
    "cat2idx = {\"Diamond\": 0, \"Egg\": 1, \"Triangle\": 2} \n",
    "\n",
    "def get_image(cat, x, y, size, rot, color_r, color_g, color_b):\n",
    "    fig, ax = plt.subplots(figsize=(32, 32), dpi=1)\n",
    "    # The dataset generatoion tool has function to generate a matplotlib shape\n",
    "    # from the attributes.\n",
    "    generate_image(\n",
    "        ax,\n",
    "        cat2idx[cat],\n",
    "        [int(x * 18 + 7), int(y * 18 + 7)],\n",
    "        size * 7 + 7,\n",
    "        rot * 2 * math.pi,\n",
    "        np.array([color_r * 255, color_g * 255, color_b * 255]),\n",
    "        imsize=32,\n",
    "    )\n",
    "    ax.set_facecolor(\"black\")\n",
    "    plt.tight_layout(pad=0)\n",
    "    # Return this as a PIL Image.\n",
    "    # This is to have the same dpi as saved images\n",
    "    # otherwise matplotlib will render this in very high quality\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf)\n",
    "    buf.seek(0)\n",
    "    image = Image.open(buf)\n",
    "    plt.close(fig)\n",
    "    return image\n",
    "\n",
    "\n",
    "@interact(\n",
    "    cat=[\"Triangle\", \"Egg\", \"Diamond\"],\n",
    "    x=(0, 1, 0.1),\n",
    "    y=(0, 1, 0.1),\n",
    "    rot=(0, 1, 0.1),\n",
    "    size=(0, 1, 0.1),\n",
    "    color_r=(0, 1, 0.1),\n",
    "    color_g=(0, 1, 0.1),\n",
    "    color_b=(0, 1, 0.1),\n",
    ")\n",
    "def play_with_gw(\n",
    "    cat: str = \"Triangle\",\n",
    "    x: float = 0.5,\n",
    "    y: float = 0.5,\n",
    "    rot: float = 0.5,\n",
    "    size: float = 0.5,\n",
    "    color_r: float = 1,\n",
    "    color_g: float = 0,\n",
    "    color_b: float = 0,\n",
    "):\n",
    "    fig, axes = plt.subplots(1, 2)\n",
    "    image = get_image(cat, x, y, size, rot, color_r, color_g, color_b)\n",
    "    axes[0].set_facecolor(\"black\")\n",
    "    axes[0].set_title(\"Original image from attributes\")\n",
    "    axes[0].set_xticks([])\n",
    "    axes[0].set_yticks([])\n",
    "    axes[0].imshow(image)\n",
    "\n",
    "    # normalize the attribute for the global workspace.\n",
    "    cat_values = one_hot(torch.tensor([cat2idx[cat]]), 3)\n",
    "    # category = category.float().unsqueeze(0)  # Add batch dimension\n",
    "    category = cat_values.float()# Add batch dimension\n",
    "    # Add batch dimension and make one-hot a little noisy\n",
    "    category = category.float()\n",
    "    # Add a small noise to make the one-hot less strict\n",
    "    noise = torch.rand_like(category) * 0.01\n",
    "    category = category + noise\n",
    "    # Normalize to ensure it still sums to 1\n",
    "    category = category / category.sum()\n",
    "    \n",
    "    \n",
    "    print(f\"Category values: {category}\")\n",
    "\n",
    "    rotx = math.cos(rot * 2 * math.pi)\n",
    "    roty = math.sin(rot * 2 * math.pi)\n",
    "    attributes = torch.tensor(\n",
    "        [[x * 2 - 1, y * 2 - 1, size * 2 - 1, rotx, roty]]# color_r * 2 - 1, color_g * 2 - 1, color_b * 2 - 1]])\n",
    "    )\n",
    "    samples = [category.to(device), attributes.to(device)]\n",
    "    attr_gw_latent = global_workspace.gw_mod.encode({\"attr\": global_workspace.encode_domain(samples, \"attr\")})\n",
    "    gw_latent = global_workspace.gw_mod.fuse(\n",
    "        attr_gw_latent, {\"attr\": torch.ones(attr_gw_latent[\"attr\"].size(0)).to(device)}\n",
    "    )\n",
    "    decoded_latents = global_workspace.gw_mod.decode(gw_latent)[\"v_latents\"]\n",
    "    decoded_images = (\n",
    "        global_workspace.domain_mods[\"v_latents\"]\n",
    "        .decode_images(decoded_latents)[0]\n",
    "        .permute(1, 2, 0)\n",
    "        .detach()\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "    axes[1].imshow(decoded_images)\n",
    "    axes[1].set_xticks([])\n",
    "    axes[1].set_yticks([])\n",
    "    axes[1].set_title(\"Translated image through GW\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_no_color",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
